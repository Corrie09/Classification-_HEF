{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d52732",
   "metadata": {},
   "source": [
    "This notebook involves new preprocessing steps (added feature engeneering, which was implemented on 22/11 at 22:58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e14a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20885, 44), (5221, 39))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"../data/\")   # full path to the HEF folder\n",
    "\n",
    "train = pd.read_csv(data_path / \"mimic_train_HEF.csv\", low_memory=False)\n",
    "test  = pd.read_csv(data_path / \"mimic_test_HEF.csv\",  low_memory=False)\n",
    "\n",
    "train.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b95932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved 5221 test IDs for submission\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAVE TEST IDs FIRST (BEFORE DROPPING!)\n",
    "# =============================================================================\n",
    "\n",
    "test_ids = test['icustay_id'].copy()\n",
    "print(f\"\\n✓ Saved {len(test_ids)} test IDs for submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7e4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. DROP LEAKAGE COLUMNS\n",
    "# =============================================================================\n",
    "columns_to_drop = [\n",
    "    'DISCHTIME', 'DEATHTIME', 'DOD', 'LOS',\n",
    "    'subject_id', 'hadm_id', 'icustay_id',\n",
    "    'ADMITTIME', 'Diff'\n",
    "]\n",
    "\n",
    "train_clean = train.drop(columns=columns_to_drop, errors='ignore')\n",
    "test_clean = test.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599153bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. SEPARATE TARGET\n",
    "# =============================================================================\n",
    "y = train_clean['HOSPITAL_EXPIRE_FLAG']\n",
    "X = train_clean.drop('HOSPITAL_EXPIRE_FLAG', axis=1)\n",
    "X_test = test_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357cffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric features: 24\n",
      "Categorical features: 10\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4. IDENTIFY FEATURE TYPES\n",
    "# =============================================================================\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05dd99c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Imputing missing values ---\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. IMPUTATION\n",
    "# =============================================================================\n",
    "print(\"\\n--- Imputing missing values ---\")\n",
    "\n",
    "# Numeric\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "X[numeric_features] = numeric_imputer.fit_transform(X[numeric_features])\n",
    "X_test[numeric_features] = numeric_imputer.transform(X_test[numeric_features])\n",
    "\n",
    "# Categorical\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X[categorical_features] = categorical_imputer.fit_transform(X[categorical_features])\n",
    "X_test[categorical_features] = categorical_imputer.transform(X_test[categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d663e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1: Converting DOB to age ---\n",
      "  ✓ Calculated age from DOB and ADMITTIME\n",
      "    Age range: 15.0 - 89.0 years\n",
      "    Mean age: 62.7 years\n",
      "    Missing ages: 1107\n",
      "    ✓ Imputed invalid ages with median: 64.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\1596579972.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['age'].fillna(age_median, inplace=True)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\1596579972.py:68: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test['age'].fillna(age_median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# STEP 1: Convert DOB to age (handling MIMIC-III date shifting)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 1: Converting DOB to age ---\")\n",
    "\n",
    "if 'DOB' in X.columns and 'DOB' in categorical_features:\n",
    "    # MIMIC-III shifts all dates forward by ~200 years for anonymization\n",
    "    # But the RELATIVE age is preserved\n",
    "    # Strategy: Calculate age = ADMITTIME - DOB\n",
    "    \n",
    "    # Reload original data to get ADMITTIME\n",
    "    train_original = pd.read_csv('../data/mimic_train_HEF.csv')\n",
    "    test_original = pd.read_csv('../data/mimic_test_HEF.csv')\n",
    "    \n",
    "    # Convert to datetime\n",
    "    dob_train = pd.to_datetime(X['DOB'], errors='coerce')\n",
    "    dob_test = pd.to_datetime(X_test['DOB'], errors='coerce')\n",
    "    admit_train = pd.to_datetime(train_original['ADMITTIME'], errors='coerce')\n",
    "    admit_test = pd.to_datetime(test_original['ADMITTIME'], errors='coerce')\n",
    "    \n",
    "    # Calculate age using timedelta and convert to years\n",
    "    # Use .apply() to avoid overflow\n",
    "    def calculate_age(admit_time, dob):\n",
    "        if pd.isna(admit_time) or pd.isna(dob):\n",
    "            return np.nan\n",
    "        try:\n",
    "            # Calculate difference in days, then convert to years\n",
    "            age_days = (admit_time - dob).days\n",
    "            age_years = age_days / 365.25\n",
    "            return age_years\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    # Calculate age for train\n",
    "    X['age'] = [calculate_age(admit, dob) for admit, dob in zip(admit_train, dob_train)]\n",
    "    \n",
    "    # Calculate age for test\n",
    "    X_test['age'] = [calculate_age(admit, dob) for admit, dob in zip(admit_test, dob_test)]\n",
    "    \n",
    "    # Convert to numeric (in case of any issues)\n",
    "    X['age'] = pd.to_numeric(X['age'], errors='coerce')\n",
    "    X_test['age'] = pd.to_numeric(X_test['age'], errors='coerce')\n",
    "    \n",
    "    # Clean up\n",
    "    X = X.drop('DOB', axis=1)\n",
    "    X_test = X_test.drop('DOB', axis=1)\n",
    "    categorical_features.remove('DOB')\n",
    "    \n",
    "    print(f\"  ✓ Calculated age from DOB and ADMITTIME\")\n",
    "    print(f\"    Age range: {X['age'].min():.1f} - {X['age'].max():.1f} years\")\n",
    "    print(f\"    Mean age: {X['age'].mean():.1f} years\")\n",
    "    print(f\"    Missing ages: {X['age'].isna().sum()}\")\n",
    "    \n",
    "    # Sanity check: ages should be reasonable (0-120 years)\n",
    "    if X['age'].max() > 120 or X['age'].min() < 0:\n",
    "        print(f\"    ⚠️ WARNING: Unusual age range detected!\")\n",
    "        print(f\"    Sample ages: {X['age'].head(10).tolist()}\")\n",
    "    \n",
    "    # Handle missing or invalid ages\n",
    "    if X['age'].isna().sum() > 0 or (X['age'] < 0).any() or (X['age'] > 120).any():\n",
    "        # Set invalid ages to NaN\n",
    "        X.loc[(X['age'] < 0) | (X['age'] > 120), 'age'] = np.nan\n",
    "        X_test.loc[(X_test['age'] < 0) | (X_test['age'] > 120), 'age'] = np.nan\n",
    "        \n",
    "        # Impute with median\n",
    "        age_median = X['age'].median()\n",
    "        X['age'].fillna(age_median, inplace=True)\n",
    "        X_test['age'].fillna(age_median, inplace=True)\n",
    "        print(f\"    ✓ Imputed invalid ages with median: {age_median:.1f}\")\n",
    "    \n",
    "    # Add to numeric features for scaling later\n",
    "    if 'age' not in numeric_features:\n",
    "        numeric_features.append('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ef4928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DIAGNOSING CATEGORICAL FEATURES\n",
      "======================================================================\n",
      "\n",
      "Total categorical features: 9\n",
      "  GENDER: 2 unique values\n",
      "    Distribution: {'M': 11759, 'F': 9126}\n",
      "  ADMISSION_TYPE: 3 unique values\n",
      "    Distribution: {'EMERGENCY': 17817, 'ELECTIVE': 2848, 'URGENT': 220}\n",
      "  INSURANCE: 5 unique values\n",
      "    Distribution: {'Medicare': 11718, 'Private': 6245, 'Medicaid': 2117, 'Government': 611, 'Self Pay': 194}\n",
      "  RELIGION: 17 unique values\n",
      "    ⚠️ HIGH CARDINALITY - will create 17 one-hot columns!\n",
      "  MARITAL_STATUS: 7 unique values\n",
      "    Distribution: {'MARRIED': 10386, 'SINGLE': 5910, 'WIDOWED': 2819, 'DIVORCED': 1413, 'SEPARATED': 240, 'UNKNOWN (DEFAULT)': 103, 'LIFE PARTNER': 14}\n",
      "  ETHNICITY: 41 unique values\n",
      "    ⚠️ HIGH CARDINALITY - will create 41 one-hot columns!\n",
      "  DIAGNOSIS: 6193 unique values\n",
      "    ⚠️ HIGH CARDINALITY - will create 6193 one-hot columns!\n",
      "  ICD9_diagnosis: 1853 unique values\n",
      "    ⚠️ HIGH CARDINALITY - will create 1853 one-hot columns!\n",
      "  FIRST_CAREUNIT: 5 unique values\n",
      "    Distribution: {'MICU': 8640, 'SICU': 3961, 'CSRU': 3127, 'TSICU': 2645, 'CCU': 2512}\n",
      "\n",
      "⚠️ ESTIMATED TOTAL FEATURES AFTER ONE-HOT ENCODING: 8142\n",
      "Current numeric features: 25\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5.5. DIAGNOSE HIGH-CARDINALITY CATEGORICAL FEATURES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIAGNOSING CATEGORICAL FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTotal categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# Check cardinality (number of unique values) for each categorical feature\n",
    "for cat_col in categorical_features:\n",
    "    n_unique = X[cat_col].nunique()\n",
    "    print(f\"  {cat_col}: {n_unique} unique values\")\n",
    "    \n",
    "    # Show distribution if few unique values\n",
    "    if n_unique <= 10:\n",
    "        print(f\"    Distribution: {X[cat_col].value_counts().to_dict()}\")\n",
    "    else:\n",
    "        print(f\"    ⚠️ HIGH CARDINALITY - will create {n_unique} one-hot columns!\")\n",
    "\n",
    "# Estimate final feature count after one-hot encoding\n",
    "estimated_features = len(numeric_features)\n",
    "for cat_col in categorical_features:\n",
    "    estimated_features += X[cat_col].nunique() - 1  # -1 because drop_first=True\n",
    "\n",
    "print(f\"\\n⚠️ ESTIMATED TOTAL FEATURES AFTER ONE-HOT ENCODING: {estimated_features}\")\n",
    "print(f\"Current numeric features: {len(numeric_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95243011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SMART CATEGORICAL ENCODING\n",
      "======================================================================\n",
      "\n",
      "--- Step 2: Processing ICD9_diagnosis codes ---\n",
      "  ✓ Extracted ICD9 categories: 530 unique categories\n",
      "  → Using target encoding for ICD9 categories\n",
      "  ✓ ICD9_diagnosis → ICD9_encoded (numeric)\n",
      "\n",
      "--- Step 3: Processing DIAGNOSIS (free text) ---\n",
      "  ✓ Dropping DIAGNOSIS (free text, 6193 unique values)\n",
      "    → Keeping ICD9_encoded instead (more structured)\n",
      "\n",
      "--- Step 4: Grouping ETHNICITY ---\n",
      "  ✓ Grouped ETHNICITY: 41 → 8 categories\n",
      "    New categories: ['ASIAN', 'BLACK', 'HISPANIC', 'NATIVE', 'OTHER', 'PACIFIC_ISLANDER', 'UNKNOWN', 'WHITE']\n",
      "    Distribution:\n",
      "      WHITE: 15330 (73.4%)\n",
      "      BLACK: 2201 (10.5%)\n",
      "      UNKNOWN: 1320 (6.3%)\n",
      "      HISPANIC: 852 (4.1%)\n",
      "      OTHER: 616 (2.9%)\n",
      "      ASIAN: 545 (2.6%)\n",
      "      NATIVE: 15 (0.1%)\n",
      "      PACIFIC_ISLANDER: 6 (0.0%)\n",
      "\n",
      "--- Step 5: Grouping RELIGION ---\n",
      "  ✓ Grouped RELIGION: 17 → 8 categories\n",
      "    New categories: ['CATHOLIC', 'JEWISH', 'MUSLIM', 'ORTHODOX', 'OTHER', 'OTHER_RELIGION', 'PROTESTANT', 'UNKNOWN']\n",
      "    Distribution:\n",
      "      CATHOLIC: 7655 (36.7%)\n",
      "      UNKNOWN: 6913 (33.1%)\n",
      "      PROTESTANT: 3041 (14.6%)\n",
      "      JEWISH: 1841 (8.8%)\n",
      "      OTHER: 743 (3.6%)\n",
      "      OTHER_RELIGION: 440 (2.1%)\n",
      "      ORTHODOX: 178 (0.9%)\n",
      "      MUSLIM: 74 (0.4%)\n",
      "\n",
      "--- Step 6: Grouping MARITAL_STATUS ---\n",
      "  ✓ Grouped MARITAL_STATUS: 7 → 5 categories\n",
      "    New categories: ['DIVORCED_SEPARATED', 'MARRIED', 'SINGLE', 'UNKNOWN', 'WIDOWED']\n",
      "    Distribution:\n",
      "      MARRIED: 10400 (49.8%)\n",
      "      SINGLE: 5910 (28.3%)\n",
      "      WIDOWED: 2819 (13.5%)\n",
      "      DIVORCED_SEPARATED: 1653 (7.9%)\n",
      "      UNKNOWN: 103 (0.5%)\n",
      "\n",
      "--- Step 7: One-hot encoding remaining categorical features ---\n",
      "\n",
      "Features to one-hot encode (7):\n",
      "  GENDER: 2 categories → 1 binary features\n",
      "  ADMISSION_TYPE: 3 categories → 2 binary features\n",
      "  INSURANCE: 5 categories → 4 binary features\n",
      "  RELIGION: 8 categories → 7 binary features\n",
      "  MARITAL_STATUS: 5 categories → 4 binary features\n",
      "  ETHNICITY: 8 categories → 7 binary features\n",
      "  FIRST_CAREUNIT: 5 categories → 4 binary features\n",
      "\n",
      "Estimated new binary features from one-hot encoding: 29\n",
      "✓ One-hot encoding complete\n",
      "\n",
      "======================================================================\n",
      "ENCODING COMPLETE - SUMMARY\n",
      "======================================================================\n",
      "Original numeric features: 26\n",
      "Target-encoded features: 1 (ICD9_encoded)\n",
      "Binary features from one-hot encoding: 29\n",
      "\n",
      "Final shapes:\n",
      "  X: (20885, 55)\n",
      "  X_test: (5221, 55)\n",
      "  Total features: 55\n",
      "\n",
      "✓ Feature count looks good (55 features)\n",
      "\n",
      "Sample of final features (first 20):\n",
      "['HeartRate_Min', 'HeartRate_Max', 'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min', 'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean', 'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min', 'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7. SMART CATEGORICAL ENCODING\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SMART CATEGORICAL ENCODING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 2: Handle ICD9_diagnosis (extract category, then target encode)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 2: Processing ICD9_diagnosis codes ---\")\n",
    "\n",
    "if 'ICD9_diagnosis' in X.columns:\n",
    "    # ICD9 codes have hierarchical structure:\n",
    "    # First digit = broad category (e.g., 4XX = circulatory system)\n",
    "    # First 3 digits = more specific category\n",
    "    \n",
    "    def extract_icd9_category(code):\n",
    "        \"\"\"Extract first 3 characters from ICD9 code\"\"\"\n",
    "        if pd.isna(code):\n",
    "            return 'UNKNOWN'\n",
    "        code_str = str(code).strip()\n",
    "        # Remove decimal point and take first 3 characters\n",
    "        code_str = code_str.replace('.', '')\n",
    "        if len(code_str) >= 3:\n",
    "            return code_str[:3]\n",
    "        elif len(code_str) > 0:\n",
    "            return code_str\n",
    "        else:\n",
    "            return 'UNKNOWN'\n",
    "    \n",
    "    X['ICD9_category'] = X['ICD9_diagnosis'].apply(extract_icd9_category)\n",
    "    X_test['ICD9_category'] = X_test['ICD9_diagnosis'].apply(extract_icd9_category)\n",
    "    \n",
    "    n_icd9_categories = X['ICD9_category'].nunique()\n",
    "    print(f\"  ✓ Extracted ICD9 categories: {n_icd9_categories} unique categories\")\n",
    "    \n",
    "    # Target encode (because still likely 100+ categories)\n",
    "    print(f\"  → Using target encoding for ICD9 categories\")\n",
    "    encoding_map = y.groupby(X['ICD9_category']).mean().to_dict()\n",
    "    global_mean = y.mean()\n",
    "    \n",
    "    X['ICD9_encoded'] = X['ICD9_category'].map(encoding_map)\n",
    "    X_test['ICD9_encoded'] = X_test['ICD9_category'].map(encoding_map).fillna(global_mean)\n",
    "    \n",
    "    # Add to numeric features (target encoding creates numeric feature)\n",
    "    numeric_features.append('ICD9_encoded')\n",
    "    \n",
    "    # Drop originals\n",
    "    X = X.drop(['ICD9_diagnosis', 'ICD9_category'], axis=1)\n",
    "    X_test = X_test.drop(['ICD9_diagnosis', 'ICD9_category'], axis=1)\n",
    "    categorical_features.remove('ICD9_diagnosis')\n",
    "    \n",
    "    print(f\"  ✓ ICD9_diagnosis → ICD9_encoded (numeric)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 3: Handle DIAGNOSIS (free text - extract keywords or drop)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 3: Processing DIAGNOSIS (free text) ---\")\n",
    "\n",
    "if 'DIAGNOSIS' in X.columns:\n",
    "    # Option 1: Drop it (safest - free text is very high cardinality)\n",
    "    # Option 2: Extract common keywords (more complex)\n",
    "    \n",
    "    # For now, let's DROP it to keep things simple\n",
    "    # (We already have ICD9 codes which are more structured)\n",
    "    \n",
    "    print(f\"  ✓ Dropping DIAGNOSIS (free text, {X['DIAGNOSIS'].nunique()} unique values)\")\n",
    "    print(f\"    → Keeping ICD9_encoded instead (more structured)\")\n",
    "    \n",
    "    X = X.drop('DIAGNOSIS', axis=1)\n",
    "    X_test = X_test.drop('DIAGNOSIS', axis=1)\n",
    "    categorical_features.remove('DIAGNOSIS')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 4: Group ETHNICITY into broader categories\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 4: Grouping ETHNICITY ---\")\n",
    "\n",
    "if 'ETHNICITY' in X.columns:\n",
    "    def group_ethnicity(ethnicity):\n",
    "        if pd.isna(ethnicity):\n",
    "            return 'UNKNOWN'\n",
    "        ethnicity = str(ethnicity).upper()\n",
    "        \n",
    "        # WHITE (includes variants like WHITE - RUSSIAN, WHITE - BRAZILIAN, etc.)\n",
    "        if 'WHITE' in ethnicity:\n",
    "            return 'WHITE'\n",
    "        \n",
    "        # BLACK (includes BLACK/AFRICAN AMERICAN, BLACK/HAITIAN, BLACK/CAPE VERDEAN, etc.)\n",
    "        elif 'BLACK' in ethnicity or 'AFRICAN' in ethnicity:\n",
    "            return 'BLACK'\n",
    "        \n",
    "        # HISPANIC/LATINO (all variants)\n",
    "        elif 'HISPANIC' in ethnicity or 'LATINO' in ethnicity:\n",
    "            return 'HISPANIC'\n",
    "        \n",
    "        # ASIAN (includes ASIAN - CHINESE, ASIAN - VIETNAMESE, etc.)\n",
    "        elif 'ASIAN' in ethnicity:\n",
    "            return 'ASIAN'\n",
    "        \n",
    "        # NATIVE/INDIGENOUS (American Indian/Alaska Native)\n",
    "        elif 'AMERICAN INDIAN' in ethnicity or 'ALASKA NATIVE' in ethnicity:\n",
    "            return 'NATIVE'\n",
    "        \n",
    "        # PACIFIC ISLANDER\n",
    "        elif 'HAWAIIAN' in ethnicity or 'PACIFIC ISLANDER' in ethnicity:\n",
    "            return 'PACIFIC_ISLANDER'\n",
    "        \n",
    "        # UNKNOWN/NOT SPECIFIED/DECLINED\n",
    "        elif any(x in ethnicity for x in ['UNKNOWN', 'UNABLE', 'DECLINED', 'NOT SPECIFIED']):\n",
    "            return 'UNKNOWN'\n",
    "        \n",
    "        # OTHER (includes MULTI RACE, MIDDLE EASTERN, CARIBBEAN, PORTUGUESE, etc.)\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    X['ETHNICITY'] = X['ETHNICITY'].apply(group_ethnicity)\n",
    "    X_test['ETHNICITY'] = X_test['ETHNICITY'].apply(group_ethnicity)\n",
    "    \n",
    "    print(f\"  ✓ Grouped ETHNICITY: 41 → {X['ETHNICITY'].nunique()} categories\")\n",
    "    print(f\"    New categories: {sorted(X['ETHNICITY'].unique())}\")\n",
    "    print(f\"    Distribution:\")\n",
    "    for cat, count in X['ETHNICITY'].value_counts().items():\n",
    "        print(f\"      {cat}: {count} ({count/len(X)*100:.1f}%)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 5: Group RELIGION into broader categories\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 5: Grouping RELIGION ---\")\n",
    "\n",
    "if 'RELIGION' in X.columns:\n",
    "    def group_religion(religion):\n",
    "        if pd.isna(religion):\n",
    "            return 'UNKNOWN'\n",
    "        religion = str(religion).upper()\n",
    "        \n",
    "        # CATHOLIC\n",
    "        if 'CATHOLIC' in religion:\n",
    "            return 'CATHOLIC'\n",
    "        \n",
    "        # PROTESTANT/CHRISTIAN (includes PROTESTANT QUAKER, EPISCOPALIAN, etc.)\n",
    "        elif any(x in religion for x in ['PROTESTANT', 'EPISCOPALIAN', 'QUAKER']):\n",
    "            return 'PROTESTANT'\n",
    "        \n",
    "        # JEWISH (includes HEBREW)\n",
    "        elif 'JEWISH' in religion or 'HEBREW' in religion:\n",
    "            return 'JEWISH'\n",
    "        \n",
    "        # MUSLIM\n",
    "        elif 'MUSLIM' in religion:\n",
    "            return 'MUSLIM'\n",
    "        \n",
    "        # ORTHODOX (GREEK ORTHODOX, ROMANIAN ORTHODOX)\n",
    "        elif 'ORTHODOX' in religion:\n",
    "            return 'ORTHODOX'\n",
    "        \n",
    "        # OTHER RELIGIONS (Buddhist, Hindu, Christian Scientist, Jehovah's Witness, etc.)\n",
    "        elif any(x in religion for x in ['BUDDHIST', 'HINDU', 'JEHOVAH', 'CHRISTIAN SCIENTIST', \n",
    "                                          '7TH DAY ADVENTIST', 'UNITARIAN']):\n",
    "            return 'OTHER_RELIGION'\n",
    "        \n",
    "        # UNKNOWN/NOT SPECIFIED\n",
    "        elif any(x in religion for x in ['UNOBTAINABLE', 'NOT SPECIFIED', 'UNKNOWN']):\n",
    "            return 'UNKNOWN'\n",
    "        \n",
    "        # OTHER\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    X['RELIGION'] = X['RELIGION'].apply(group_religion)\n",
    "    X_test['RELIGION'] = X_test['RELIGION'].apply(group_religion)\n",
    "    \n",
    "    print(f\"  ✓ Grouped RELIGION: 17 → {X['RELIGION'].nunique()} categories\")\n",
    "    print(f\"    New categories: {sorted(X['RELIGION'].unique())}\")\n",
    "    print(f\"    Distribution:\")\n",
    "    for cat, count in X['RELIGION'].value_counts().items():\n",
    "        print(f\"      {cat}: {count} ({count/len(X)*100:.1f}%)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 6: Group MARITAL_STATUS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 6: Grouping MARITAL_STATUS ---\")\n",
    "\n",
    "if 'MARITAL_STATUS' in X.columns:\n",
    "    def group_marital_status(status):\n",
    "        if pd.isna(status):\n",
    "            return 'UNKNOWN'\n",
    "        status = str(status).upper()\n",
    "        \n",
    "        # MARRIED (includes LIFE PARTNER)\n",
    "        if 'MARRIED' in status or 'LIFE PARTNER' in status:\n",
    "            return 'MARRIED'\n",
    "        \n",
    "        # SINGLE\n",
    "        elif 'SINGLE' in status:\n",
    "            return 'SINGLE'\n",
    "        \n",
    "        # WIDOWED\n",
    "        elif 'WIDOWED' in status:\n",
    "            return 'WIDOWED'\n",
    "        \n",
    "        # DIVORCED/SEPARATED (group together - both indicate ended relationship)\n",
    "        elif 'DIVORCED' in status or 'SEPARATED' in status:\n",
    "            return 'DIVORCED_SEPARATED'\n",
    "        \n",
    "        # UNKNOWN\n",
    "        elif 'UNKNOWN' in status:\n",
    "            return 'UNKNOWN'\n",
    "        \n",
    "        else:\n",
    "            return 'UNKNOWN'\n",
    "    \n",
    "    X['MARITAL_STATUS'] = X['MARITAL_STATUS'].apply(group_marital_status)\n",
    "    X_test['MARITAL_STATUS'] = X_test['MARITAL_STATUS'].apply(group_marital_status)\n",
    "    \n",
    "    print(f\"  ✓ Grouped MARITAL_STATUS: 7 → {X['MARITAL_STATUS'].nunique()} categories\")\n",
    "    print(f\"    New categories: {sorted(X['MARITAL_STATUS'].unique())}\")\n",
    "    print(f\"    Distribution:\")\n",
    "    for cat, count in X['MARITAL_STATUS'].value_counts().items():\n",
    "        print(f\"      {cat}: {count} ({count/len(X)*100:.1f}%)\")\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 7: One-hot encode remaining low-cardinality features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 7: One-hot encoding remaining categorical features ---\")\n",
    "\n",
    "# Update categorical_features list\n",
    "remaining_categorical = [col for col in categorical_features if col in X.columns]\n",
    "print(f\"\\nFeatures to one-hot encode ({len(remaining_categorical)}):\")\n",
    "\n",
    "# Verify cardinality\n",
    "total_new_features = 0\n",
    "for col in remaining_categorical:\n",
    "    n_unique = X[col].nunique()\n",
    "    total_new_features += (n_unique - 1)  # drop_first=True\n",
    "    print(f\"  {col}: {n_unique} categories → {n_unique-1} binary features\")\n",
    "\n",
    "print(f\"\\nEstimated new binary features from one-hot encoding: {total_new_features}\")\n",
    "\n",
    "if len(remaining_categorical) > 0:\n",
    "    # One-hot encode\n",
    "    X_combined = pd.concat([X, X_test], keys=['train', 'test'])\n",
    "    X_encoded = pd.get_dummies(X_combined, columns=remaining_categorical, drop_first=True)\n",
    "    X = X_encoded.xs('train')\n",
    "    X_test = X_encoded.xs('test')\n",
    "    \n",
    "    print(f\"✓ One-hot encoding complete\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# FINAL SUMMARY\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENCODING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Original numeric features: {len(numeric_features)}\")\n",
    "print(f\"Target-encoded features: 1 (ICD9_encoded)\")\n",
    "print(f\"Binary features from one-hot encoding: {total_new_features}\")\n",
    "print(f\"\\nFinal shapes:\")\n",
    "print(f\"  X: {X.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  Total features: {X.shape[1]}\")\n",
    "\n",
    "# Check if reasonable\n",
    "if X.shape[1] > 200:\n",
    "    print(f\"\\n⚠️ WARNING: {X.shape[1]} features might still be too many\")\n",
    "    print(\"Consider more aggressive grouping or feature selection\")\n",
    "elif X.shape[1] < 50:\n",
    "    print(f\"\\n⚠️ WARNING: Only {X.shape[1]} features - might be too few\")\n",
    "    print(\"Consider keeping more granular categories\")\n",
    "else:\n",
    "    print(f\"\\n✓ Feature count looks good ({X.shape[1]} features)\")\n",
    "\n",
    "# Show a sample of the final feature names\n",
    "print(f\"\\nSample of final features (first 20):\")\n",
    "print(list(X.columns[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca357bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRANSFORMING SKEWED FEATURES\n",
      "======================================================================\n",
      "  ✓ Log-transformed Glucose_Max\n",
      "  ✓ Log-transformed Glucose_Mean\n",
      "  ✓ Log-transformed Glucose_Min\n",
      "  ✓ Log-transformed MeanBP_Max\n",
      "\n",
      "Transformed 4 skewed features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\953503949.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feat] = np.log1p(X[feat] - X[feat].min() + 1)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\953503949.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feat] = np.log1p(X_test[feat] - X_test[feat].min() + 1)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7.5. TRANSFORM SKEWED FEATURES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSFORMING SKEWED FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Apply log transformation to highly skewed features\n",
    "# This helps models learn better from skewed distributions\n",
    "\n",
    "skewed_features_to_transform = [\n",
    "    'Glucose_Max', 'Glucose_Mean', 'Glucose_Min', 'Glucose_Range',\n",
    "    'MeanBP_Max', 'Temp_Range', 'age_squared'\n",
    "]\n",
    "\n",
    "for feat in skewed_features_to_transform:\n",
    "    if feat in X.columns:\n",
    "        # Add 1 to handle any zeros, then log transform\n",
    "        X[feat] = np.log1p(X[feat] - X[feat].min() + 1)\n",
    "        X_test[feat] = np.log1p(X_test[feat] - X_test[feat].min() + 1)\n",
    "        print(f\"  ✓ Log-transformed {feat}\")\n",
    "\n",
    "print(f\"\\nTransformed {len([f for f in skewed_features_to_transform if f in X.columns])} skewed features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4743b5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SCALING NUMERIC FEATURES\n",
      "======================================================================\n",
      "Total numeric features to process: 26\n",
      "\n",
      "Feature classification:\n",
      "  Binary features (will NOT scale): 0\n",
      "  Continuous features (will scale): 26\n",
      "\n",
      "✓ Scaled 26 continuous features\n",
      "✓ Left 0 binary features unscaled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2512229183.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[continuous_features] = scaler.fit_transform(X[continuous_features])\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2512229183.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[continuous_features] = scaler.transform(X_test[continuous_features])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. FEATURE SCALING\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCALING NUMERIC FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Identify numeric columns after encoding (one-hot creates binary columns)\n",
    "# Only scale original numeric features + engineered features\n",
    "numeric_cols_to_scale = [col for col in numeric_features if col in X.columns]\n",
    "\n",
    "# Add engineered features to the list (they were created after numeric_features was defined)\n",
    "engineered_numeric = ['PulsePressure', 'SysBP_Range', 'ShockIndex', 'ModifiedShockIndex',\n",
    "                      'RespDistress_Score', 'Temp_Range', 'Glucose_Range', 'HeartRate_Range',\n",
    "                      'age_squared', 'Severity_Score']\n",
    "for feat in engineered_numeric:\n",
    "    if feat in X.columns and feat not in numeric_cols_to_scale:\n",
    "        numeric_cols_to_scale.append(feat)\n",
    "\n",
    "print(f\"Total numeric features to process: {len(numeric_cols_to_scale)}\")\n",
    "\n",
    "# Separate binary indicators from continuous features\n",
    "# Binary features should NOT be scaled (would destroy their meaning)\n",
    "binary_features = []\n",
    "continuous_features = []\n",
    "\n",
    "for col in numeric_cols_to_scale:\n",
    "    unique_count = X[col].nunique()\n",
    "    unique_values = set(X[col].unique())\n",
    "    \n",
    "    # Check if binary (only 0 and 1, or just one value after one-hot encoding)\n",
    "    is_binary = (unique_count <= 2 and \n",
    "                 (unique_values.issubset({0, 1}) or \n",
    "                  unique_values.issubset({0.0, 1.0}) or\n",
    "                  unique_values.issubset({0, 1, 0.0, 1.0})))\n",
    "    \n",
    "    if is_binary:\n",
    "        binary_features.append(col)\n",
    "    else:\n",
    "        continuous_features.append(col)\n",
    "\n",
    "print(f\"\\nFeature classification:\")\n",
    "print(f\"  Binary features (will NOT scale): {len(binary_features)}\")\n",
    "print(f\"  Continuous features (will scale): {len(continuous_features)}\")\n",
    "\n",
    "# Scale only continuous features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "if len(continuous_features) > 0:\n",
    "    X[continuous_features] = scaler.fit_transform(X[continuous_features])\n",
    "    X_test[continuous_features] = scaler.transform(X_test[continuous_features])\n",
    "    print(f\"\\n✓ Scaled {len(continuous_features)} continuous features\")\n",
    "else:\n",
    "    print(\"\\n⚠ No continuous features found to scale\")\n",
    "\n",
    "print(f\"✓ Left {len(binary_features)} binary features unscaled\")\n",
    "\n",
    "# Verify some binary features retained their 0/1 values\n",
    "if len(binary_features) > 0:\n",
    "    print(\"\\nVerifying binary features (sample of 5):\")\n",
    "    for feat in binary_features[:5]:\n",
    "        unique_vals = sorted(X[feat].unique())\n",
    "        print(f\"  {feat}: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "308d0add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "--- Blood Pressure Features ---\n",
      "  ✓ Pulse pressure\n",
      "  ✓ Systolic BP range\n",
      "\n",
      "--- Shock Indices ---\n",
      "  ✓ Shock index (HR/SysBP) - capped at [0, 3]\n",
      "  ✓ Modified shock index (HR/MAP) - capped at [0, 3]\n",
      "\n",
      "--- Respiratory Features ---\n",
      "  ✓ Hypoxemia (SpO2 < 90%)\n",
      "  ✓ Abnormal respiratory rate\n",
      "  ✓ Respiratory distress score\n",
      "\n",
      "--- Temperature Features ---\n",
      "  ✓ Fever indicator\n",
      "  ✓ Hypothermia indicator\n",
      "  ✓ Temperature range\n",
      "\n",
      "--- Glucose Features ---\n",
      "  ✓ Hyperglycemia (>180 mg/dL)\n",
      "  ✓ Hypoglycemia (<70 mg/dL)\n",
      "  ✓ Glucose variability\n",
      "\n",
      "--- Age-Related Features ---\n",
      "  ✓ Elderly indicator (>65 years)\n",
      "  ✓ Age squared\n",
      "\n",
      "--- Vital Sign Variability ---\n",
      "  ✓ Heart rate range\n",
      "\n",
      "--- Composite Risk Score ---\n",
      "  ✓ Composite severity score (0-5)\n",
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING COMPLETE\n",
      "======================================================================\n",
      "Original features: 55\n",
      "New features: 72\n",
      "Added: 17 engineered features\n",
      "\n",
      "Engineered features added to numeric_features list for scaling\n",
      "\n",
      "--- Removing Redundant Features ---\n",
      "  ✓ Dropped RespDistress_Score (redundant with RespRate_Mean)\n",
      "  ✓ Dropped MeanBP_Mean (redundant with DiasBP_Mean)\n",
      "\n",
      "Removed 2 redundant features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['PulsePressure'] = X['SysBP_Mean'] - X['DiasBP_Mean']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['PulsePressure'] = X_test['SysBP_Mean'] - X_test['DiasBP_Mean']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['SysBP_Range'] = X['SysBP_Max'] - X['SysBP_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['SysBP_Range'] = X_test['SysBP_Max'] - X_test['SysBP_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ShockIndex'] = X['HeartRate_Mean'] / (X['SysBP_Mean'] + 1)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['ShockIndex'] = X_test['HeartRate_Mean'] / (X_test['SysBP_Mean'] + 1)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ShockIndex'] = X['ShockIndex'].clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['ShockIndex'] = X_test['ShockIndex'].clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ModifiedShockIndex'] = X['HeartRate_Mean'] / (X['MeanBP_Mean'] + 1)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['ModifiedShockIndex'] = X_test['HeartRate_Mean'] / (X_test['MeanBP_Mean'] + 1)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ModifiedShockIndex'] = X['ModifiedShockIndex'].clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['ModifiedShockIndex'] = X_test['ModifiedShockIndex'].clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hypoxemia'] = (X['SpO2_Min'] < 90).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hypoxemia'] = (X_test['SpO2_Min'] < 90).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['RespRate_Abnormal'] = ((X['RespRate_Mean'] < 12) | (X['RespRate_Mean'] > 20)).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['RespRate_Abnormal'] = ((X_test['RespRate_Mean'] < 12) | (X_test['RespRate_Mean'] > 20)).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['RespDistress_Score'] = X['RespRate_Mean'] * (100 - X['SpO2_Mean'])\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['RespDistress_Score'] = X_test['RespRate_Mean'] * (100 - X_test['SpO2_Mean'])\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Fever'] = (X['TempC_Max'] > 38).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Fever'] = (X_test['TempC_Max'] > 38).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hypothermia'] = (X['TempC_Min'] < 36).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hypothermia'] = (X_test['TempC_Min'] < 36).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Temp_Range'] = X['TempC_Max'] - X['TempC_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Temp_Range'] = X_test['TempC_Max'] - X_test['TempC_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hyperglycemia'] = (X['Glucose_Max'] > 180).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hyperglycemia'] = (X_test['Glucose_Max'] > 180).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hypoglycemia'] = (X['Glucose_Min'] < 70).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hypoglycemia'] = (X_test['Glucose_Min'] < 70).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Glucose_Range'] = X['Glucose_Max'] - X['Glucose_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Glucose_Range'] = X_test['Glucose_Max'] - X_test['Glucose_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Elderly'] = (X['age'] > 65).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:129: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Elderly'] = (X_test['age'] > 65).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['age_squared'] = X['age'] ** 2\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['age_squared'] = X_test['age'] ** 2\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:144: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['HeartRate_Range'] = X['HeartRate_Max'] - X['HeartRate_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['HeartRate_Range'] = X_test['HeartRate_Max'] - X_test['HeartRate_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Severity_Score'] = sum(severity_components)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_29328\\2847557397.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Severity_Score'] = sum(severity_components_test)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8.5. FEATURE ENGINEERING - MEDICAL DOMAIN KNOWLEDGE\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "original_feature_count = X.shape[1]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Blood Pressure Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Blood Pressure Features ---\")\n",
    "\n",
    "# Pulse Pressure (SysBP - DiasBP) - cardiovascular health indicator\n",
    "if all(col in X.columns for col in ['SysBP_Mean', 'DiasBP_Mean']):\n",
    "    X['PulsePressure'] = X['SysBP_Mean'] - X['DiasBP_Mean']\n",
    "    X_test['PulsePressure'] = X_test['SysBP_Mean'] - X_test['DiasBP_Mean']\n",
    "    print(\"  ✓ Pulse pressure\")\n",
    "\n",
    "# Blood pressure variability\n",
    "if all(col in X.columns for col in ['SysBP_Min', 'SysBP_Max']):\n",
    "    X['SysBP_Range'] = X['SysBP_Max'] - X['SysBP_Min']\n",
    "    X_test['SysBP_Range'] = X_test['SysBP_Max'] - X_test['SysBP_Min']\n",
    "    print(\"  ✓ Systolic BP range\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Shock Indices (Critical for ICU mortality prediction)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Shock Indices ---\")\n",
    "\n",
    "# Shock Index = HR / SysBP (>0.9 indicates shock)\n",
    "if all(col in X.columns for col in ['HeartRate_Mean', 'SysBP_Mean']):\n",
    "    X['ShockIndex'] = X['HeartRate_Mean'] / (X['SysBP_Mean'] + 1)\n",
    "    X_test['ShockIndex'] = X_test['HeartRate_Mean'] / (X_test['SysBP_Mean'] + 1)\n",
    "    \n",
    "    # Cap extreme values (clinical range: 0.5-2.0 is reasonable)\n",
    "    X['ShockIndex'] = X['ShockIndex'].clip(0, 3)\n",
    "    X_test['ShockIndex'] = X_test['ShockIndex'].clip(0, 3)\n",
    "    print(\"  ✓ Shock index (HR/SysBP) - capped at [0, 3]\")\n",
    "\n",
    "# Modified Shock Index = HR / MAP\n",
    "if all(col in X.columns for col in ['HeartRate_Mean', 'MeanBP_Mean']):\n",
    "    X['ModifiedShockIndex'] = X['HeartRate_Mean'] / (X['MeanBP_Mean'] + 1)\n",
    "    X_test['ModifiedShockIndex'] = X_test['HeartRate_Mean'] / (X_test['MeanBP_Mean'] + 1)\n",
    "    \n",
    "    # Cap extreme values\n",
    "    X['ModifiedShockIndex'] = X['ModifiedShockIndex'].clip(0, 3)\n",
    "    X_test['ModifiedShockIndex'] = X_test['ModifiedShockIndex'].clip(0, 3)\n",
    "    print(\"  ✓ Modified shock index (HR/MAP) - capped at [0, 3]\")\n",
    "    \n",
    "# -----------------------------------------------------------------------------\n",
    "# Respiratory Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Respiratory Features ---\")\n",
    "\n",
    "# Hypoxemia indicator (SpO2 < 90% is clinically significant)\n",
    "if 'SpO2_Min' in X.columns:\n",
    "    X['Hypoxemia'] = (X['SpO2_Min'] < 90).astype(int)\n",
    "    X_test['Hypoxemia'] = (X_test['SpO2_Min'] < 90).astype(int)\n",
    "    print(\"  ✓ Hypoxemia (SpO2 < 90%)\")\n",
    "\n",
    "# Respiratory rate abnormality (normal: 12-20 breaths/min)\n",
    "if 'RespRate_Mean' in X.columns:\n",
    "    X['RespRate_Abnormal'] = ((X['RespRate_Mean'] < 12) | (X['RespRate_Mean'] > 20)).astype(int)\n",
    "    X_test['RespRate_Abnormal'] = ((X_test['RespRate_Mean'] < 12) | (X_test['RespRate_Mean'] > 20)).astype(int)\n",
    "    print(\"  ✓ Abnormal respiratory rate\")\n",
    "\n",
    "# Respiratory distress score (high RR + low SpO2)\n",
    "if all(col in X.columns for col in ['RespRate_Mean', 'SpO2_Mean']):\n",
    "    X['RespDistress_Score'] = X['RespRate_Mean'] * (100 - X['SpO2_Mean'])\n",
    "    X_test['RespDistress_Score'] = X_test['RespRate_Mean'] * (100 - X_test['SpO2_Mean'])\n",
    "    print(\"  ✓ Respiratory distress score\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Temperature Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Temperature Features ---\")\n",
    "\n",
    "# Fever (>38°C)\n",
    "if 'TempC_Max' in X.columns:\n",
    "    X['Fever'] = (X['TempC_Max'] > 38).astype(int)\n",
    "    X_test['Fever'] = (X_test['TempC_Max'] > 38).astype(int)\n",
    "    print(\"  ✓ Fever indicator\")\n",
    "\n",
    "# Hypothermia (<36°C)\n",
    "if 'TempC_Min' in X.columns:\n",
    "    X['Hypothermia'] = (X['TempC_Min'] < 36).astype(int)\n",
    "    X_test['Hypothermia'] = (X_test['TempC_Min'] < 36).astype(int)\n",
    "    print(\"  ✓ Hypothermia indicator\")\n",
    "\n",
    "# Temperature instability\n",
    "if all(col in X.columns for col in ['TempC_Min', 'TempC_Max']):\n",
    "    X['Temp_Range'] = X['TempC_Max'] - X['TempC_Min']\n",
    "    X_test['Temp_Range'] = X_test['TempC_Max'] - X_test['TempC_Min']\n",
    "    print(\"  ✓ Temperature range\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Glucose Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Glucose Features ---\")\n",
    "\n",
    "# Hyperglycemia (>180 mg/dL)\n",
    "if 'Glucose_Max' in X.columns:\n",
    "    X['Hyperglycemia'] = (X['Glucose_Max'] > 180).astype(int)\n",
    "    X_test['Hyperglycemia'] = (X_test['Glucose_Max'] > 180).astype(int)\n",
    "    print(\"  ✓ Hyperglycemia (>180 mg/dL)\")\n",
    "\n",
    "# Hypoglycemia (<70 mg/dL)\n",
    "if 'Glucose_Min' in X.columns:\n",
    "    X['Hypoglycemia'] = (X['Glucose_Min'] < 70).astype(int)\n",
    "    X_test['Hypoglycemia'] = (X_test['Glucose_Min'] < 70).astype(int)\n",
    "    print(\"  ✓ Hypoglycemia (<70 mg/dL)\")\n",
    "\n",
    "# Glucose variability\n",
    "if all(col in X.columns for col in ['Glucose_Min', 'Glucose_Max']):\n",
    "    X['Glucose_Range'] = X['Glucose_Max'] - X['Glucose_Min']\n",
    "    X_test['Glucose_Range'] = X_test['Glucose_Max'] - X_test['Glucose_Min']\n",
    "    print(\"  ✓ Glucose variability\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Age-Related Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Age-Related Features ---\")\n",
    "\n",
    "# Elderly indicator (>65 years)\n",
    "if 'age' in X.columns:\n",
    "    X['Elderly'] = (X['age'] > 65).astype(int)\n",
    "    X_test['Elderly'] = (X_test['age'] > 65).astype(int)\n",
    "    print(\"  ✓ Elderly indicator (>65 years)\")\n",
    "    \n",
    "    # Age squared (capture non-linear effects)\n",
    "    X['age_squared'] = X['age'] ** 2\n",
    "    X_test['age_squared'] = X_test['age'] ** 2\n",
    "    print(\"  ✓ Age squared\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Vital Sign Variability\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Vital Sign Variability ---\")\n",
    "\n",
    "# Heart rate variability\n",
    "if all(col in X.columns for col in ['HeartRate_Min', 'HeartRate_Max']):\n",
    "    X['HeartRate_Range'] = X['HeartRate_Max'] - X['HeartRate_Min']\n",
    "    X_test['HeartRate_Range'] = X_test['HeartRate_Max'] - X_test['HeartRate_Min']\n",
    "    print(\"  ✓ Heart rate range\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Composite Risk Score\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Composite Risk Score ---\")\n",
    "\n",
    "# Count abnormal vital signs\n",
    "severity_components = []\n",
    "\n",
    "if 'ShockIndex' in X.columns:\n",
    "    severity_components.append((X['ShockIndex'] > 0.9).astype(int))\n",
    "if 'Hypoxemia' in X.columns:\n",
    "    severity_components.append(X['Hypoxemia'])\n",
    "if 'RespRate_Abnormal' in X.columns:\n",
    "    severity_components.append(X['RespRate_Abnormal'])\n",
    "if 'Fever' in X.columns:\n",
    "    severity_components.append(X['Fever'])\n",
    "if 'Hypothermia' in X.columns:\n",
    "    severity_components.append(X['Hypothermia'])\n",
    "\n",
    "if severity_components:\n",
    "    X['Severity_Score'] = sum(severity_components)\n",
    "    \n",
    "    # Repeat for test set\n",
    "    severity_components_test = []\n",
    "    if 'ShockIndex' in X_test.columns:\n",
    "        severity_components_test.append((X_test['ShockIndex'] > 0.9).astype(int))\n",
    "    if 'Hypoxemia' in X_test.columns:\n",
    "        severity_components_test.append(X_test['Hypoxemia'])\n",
    "    if 'RespRate_Abnormal' in X_test.columns:\n",
    "        severity_components_test.append(X_test['RespRate_Abnormal'])\n",
    "    if 'Fever' in X_test.columns:\n",
    "        severity_components_test.append(X_test['Fever'])\n",
    "    if 'Hypothermia' in X_test.columns:\n",
    "        severity_components_test.append(X_test['Hypothermia'])\n",
    "    \n",
    "    X_test['Severity_Score'] = sum(severity_components_test)\n",
    "    print(\"  ✓ Composite severity score (0-5)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Summary\n",
    "# -----------------------------------------------------------------------------\n",
    "new_feature_count = X.shape[1]\n",
    "added_features = new_feature_count - original_feature_count\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FEATURE ENGINEERING COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Original features: {original_feature_count}\")\n",
    "print(f\"New features: {new_feature_count}\")\n",
    "print(f\"Added: {added_features} engineered features\")\n",
    "\n",
    "# Update numeric_features list to include new engineered features\n",
    "new_engineered_features = [col for col in X.columns if col not in numeric_features + ['ICD9_encoded']]\n",
    "numeric_features.extend(new_engineered_features)\n",
    "\n",
    "print(f\"\\nEngineered features added to numeric_features list for scaling\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Remove Redundant Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Removing Redundant Features ---\")\n",
    "\n",
    "redundant_features = []\n",
    "\n",
    "# RespDistress_Score is 99.99% correlated with RespRate_Mean\n",
    "# Keep RespRate_Mean (original feature) and drop engineered one\n",
    "if 'RespDistress_Score' in X.columns:\n",
    "    X = X.drop('RespDistress_Score', axis=1)\n",
    "    X_test = X_test.drop('RespDistress_Score', axis=1)\n",
    "    redundant_features.append('RespDistress_Score')\n",
    "    print(\"  ✓ Dropped RespDistress_Score (redundant with RespRate_Mean)\")\n",
    "\n",
    "# MeanBP_Mean is 90% correlated with DiasBP_Mean\n",
    "# Keep DiasBP_Mean and drop MeanBP_Mean\n",
    "if 'MeanBP_Mean' in X.columns:\n",
    "    X = X.drop('MeanBP_Mean', axis=1)\n",
    "    X_test = X_test.drop('MeanBP_Mean', axis=1)\n",
    "    redundant_features.append('MeanBP_Mean')\n",
    "    print(\"  ✓ Dropped MeanBP_Mean (redundant with DiasBP_Mean)\")\n",
    "\n",
    "if redundant_features:\n",
    "    print(f\"\\nRemoved {len(redundant_features)} redundant features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40a4fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving processed data ---\n",
      "✓ Processed data saved to ../data/processed/\n",
      "\n",
      "======================================================================\n",
      "PREPROCESSING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "You can now run modeling notebooks without repeating preprocessing.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. SAVE PROCESSED DATA\n",
    "# =============================================================================\n",
    "print(\"\\n--- Saving processed data ---\")\n",
    "\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save as pickle (preserves dtypes and column names)\n",
    "X.to_pickle('../data/processed/X_train_processed.pkl')\n",
    "y.to_pickle('../data/processed/y_train.pkl')\n",
    "X_test.to_pickle('../data/processed/X_test_processed.pkl')\n",
    "test_ids.to_pickle('../data/processed/test_ids.pkl')\n",
    "\n",
    "# Also save preprocessing objects (to use on new data if needed)\n",
    "with open('../data/processed/numeric_imputer.pkl', 'wb') as f:\n",
    "    pickle.dump(numeric_imputer, f)\n",
    "with open('../data/processed/categorical_imputer.pkl', 'wb') as f:\n",
    "    pickle.dump(categorical_imputer, f)\n",
    "with open('../data/processed/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"✓ Processed data saved to ../data/processed/\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYou can now run modeling notebooks without repeating preprocessing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classification _HEF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
