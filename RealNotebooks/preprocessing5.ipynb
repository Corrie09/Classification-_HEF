{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d52732",
   "metadata": {},
   "source": [
    "This notebook involves new preprocessing steps (added feature engeneering, which was implemented on 28/11 at 21:10)   met de nieuwe stappen aangerdan door de ta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e14a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20885, 44), (5221, 39))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"../data/\")   # full path to the HEF folder\n",
    "\n",
    "train = pd.read_csv(data_path / \"mimic_train_HEF.csv\", low_memory=False)\n",
    "test  = pd.read_csv(data_path / \"mimic_test_HEF.csv\",  low_memory=False)\n",
    "\n",
    "train.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2fc954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENHANCED PREPROCESSING WITH HOSPITAL HISTORY + ICD9\n",
      "======================================================================\n",
      "\n",
      "--- Loading data sources ---\n",
      "Train: (20885, 44)\n",
      "Test: (5221, 39)\n",
      "Diagnoses: (651047, 4)\n",
      "\n",
      "======================================================================\n",
      "CREATING HOSPITAL HISTORY FEATURES\n",
      "======================================================================\n",
      "\n",
      "  âœ“ Created history features:\n",
      "    - n_previous_icu_stays (mean: 0.40)\n",
      "    - is_first_icu_visit (16317 first visits)\n",
      "    - n_previous_admissions (mean: 0.37)\n",
      "    - days_since_last_admission (median: 46.6 days)\n",
      "    - is_frequent_flyer (3388 frequent flyers)\n",
      "\n",
      "  âœ“ Created history features:\n",
      "    - n_previous_icu_stays (mean: 0.09)\n",
      "    - is_first_icu_visit (4847 first visits)\n",
      "    - n_previous_admissions (mean: 0.09)\n",
      "    - days_since_last_admission (median: 93.5 days)\n",
      "    - is_frequent_flyer (172 frequent flyers)\n",
      "\n",
      "======================================================================\n",
      "CREATING ICD9 DIAGNOSIS FEATURES\n",
      "======================================================================\n",
      "\n",
      "  âœ“ n_diagnoses (mean: 14.8)\n",
      "  âœ“ primary_diagnosis (20885 found)\n",
      "  âœ“ primary_diag_category (530 categories)\n",
      "  âœ“ primary_major_category:\n",
      "    BLOOD: 7507 (35.9%)\n",
      "    MENTAL: 3912 (18.7%)\n",
      "    INFECTIOUS: 3208 (15.4%)\n",
      "    CIRCULATORY: 1795 (8.6%)\n",
      "    RESPIRATORY: 1578 (7.6%)\n",
      "\n",
      "  Creating condition flags...\n",
      "  âœ“ Condition flags:\n",
      "    has_sepsis: 2805 (13.4%)\n",
      "    has_heart_failure: 5463 (26.2%)\n",
      "    has_resp_failure: 6116 (29.3%)\n",
      "    has_aki: 5842 (28.0%)\n",
      "    has_diabetes_comp: 6125 (29.3%)\n",
      "\n",
      "======================================================================\n",
      "STANDARD PREPROCESSING\n",
      "======================================================================\n",
      "\n",
      "After ID removal: 49 features\n",
      "Numeric: 37, Categorical: 12\n",
      "\n",
      "--- Imputation ---\n",
      "âœ“ Imputation complete\n",
      "\n",
      "--- Converting DOB to age ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:319: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['age'].fillna(age_median, inplace=True)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:320: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test['age'].fillna(age_median, inplace=True)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:495: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['PulsePressure'] = X['SysBP_Mean'] - X['DiasBP_Mean']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:496: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['PulsePressure'] = X_test['SysBP_Mean'] - X_test['DiasBP_Mean']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:499: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['SysBP_Range'] = X['SysBP_Max'] - X['SysBP_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:500: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['SysBP_Range'] = X_test['SysBP_Max'] - X_test['SysBP_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:504: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ShockIndex'] = (X['HeartRate_Mean'] / (X['SysBP_Mean'] + 1)).clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:505: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['ShockIndex'] = (X_test['HeartRate_Mean'] / (X_test['SysBP_Mean'] + 1)).clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:508: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ModifiedShockIndex'] = (X['HeartRate_Mean'] / (X['MeanBP_Mean'] + 1)).clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['ModifiedShockIndex'] = (X_test['HeartRate_Mean'] / (X_test['MeanBP_Mean'] + 1)).clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:513: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hypoxemia'] = (X['SpO2_Min'] < 90).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:514: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hypoxemia'] = (X_test['SpO2_Min'] < 90).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['RespRate_Abnormal'] = ((X['RespRate_Mean'] < 12) | (X['RespRate_Mean'] > 20)).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:518: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['RespRate_Abnormal'] = ((X_test['RespRate_Mean'] < 12) | (X_test['RespRate_Mean'] > 20)).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:522: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Fever'] = (X['TempC_Max'] > 38).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Fever'] = (X_test['TempC_Max'] > 38).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:526: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hypothermia'] = (X['TempC_Min'] < 36).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:527: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hypothermia'] = (X_test['TempC_Min'] < 36).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:530: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Temp_Range'] = X['TempC_Max'] - X['TempC_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:531: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Temp_Range'] = X_test['TempC_Max'] - X_test['TempC_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:535: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hyperglycemia'] = (X['Glucose_Max'] > 180).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:536: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hyperglycemia'] = (X_test['Glucose_Max'] > 180).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:539: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hypoglycemia'] = (X['Glucose_Min'] < 70).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:540: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hypoglycemia'] = (X_test['Glucose_Min'] < 70).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Glucose_Range'] = X['Glucose_Max'] - X['Glucose_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:544: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Glucose_Range'] = X_test['Glucose_Max'] - X_test['Glucose_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:548: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Elderly'] = (X['age'] > 65).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:549: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Elderly'] = (X_test['age'] > 65).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:551: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['age_squared'] = X['age'] ** 2\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:552: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['age_squared'] = X_test['age'] ** 2\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:555: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['age_risk_group'] = pd.cut(X['age'],\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_18272\\3468355606.py:558: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['age_risk_group'] = pd.cut(X_test['age'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Age: 0.0 - 120.0 years\n",
      "\n",
      "--- Target encoding primary diagnosis ---\n",
      "âœ“ Primary diagnosis encoded (mortality rates: 0.000 - 1.000)\n",
      "\n",
      "--- Processing categorical features ---\n",
      "âœ“ ICD9_diagnosis encoded\n",
      "âœ“ Categorical encoding complete\n",
      "\n",
      "--- Feature engineering (vitals) ---\n",
      "âœ“ Added 20 engineered features\n",
      "\n",
      "--- Scaling ---\n",
      "âœ“ Scaled 42 continuous features\n",
      "âœ“ Left 63 binary features unscaled\n",
      "\n",
      "--- Saving ---\n",
      "âœ“ Saved to ../data/processed_enhanced/\n",
      "\n",
      "======================================================================\n",
      "PREPROCESSING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Final feature count: 97\n",
      "  Original vitals: ~35\n",
      "  Hospital history: ~5\n",
      "  ICD9 diagnoses: ~6\n",
      "  Condition flags: 5\n",
      "  Engineered: ~20\n",
      "  One-hot encoded: ~26\n",
      "\n",
      "ðŸŽ¯ Ready to train models with enhanced features!\n",
      "   Expected improvement: significant boost from hospital history + diagnoses\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ENHANCED PREPROCESSING - Hospital History + ICD9 Diagnoses\n",
    "# Based on TA hints for significant improvement\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"../data/\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENHANCED PREPROCESSING WITH HOSPITAL HISTORY + ICD9\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. LOAD ALL DATA SOURCES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Loading data sources ---\")\n",
    "\n",
    "# Main datasets (keep IDs this time!)\n",
    "train = pd.read_csv(data_path / \"mimic_train_HEF.csv\", low_memory=False)\n",
    "test = pd.read_csv(data_path / \"mimic_test_HEF.csv\", low_memory=False)\n",
    "\n",
    "# Diagnoses\n",
    "diagnoses = pd.read_csv(data_path / \"extra_data\" / \"MIMIC_diagnoses.csv\")\n",
    "\n",
    "print(f\"Train: {train.shape}\")\n",
    "print(f\"Test: {test.shape}\")\n",
    "print(f\"Diagnoses: {diagnoses.shape}\")\n",
    "\n",
    "# Save test IDs\n",
    "test_ids = test['icustay_id'].copy()\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CREATE HOSPITAL HISTORY FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING HOSPITAL HISTORY FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def create_history_features(df):\n",
    "    \"\"\"\n",
    "    Create features based on patient's hospital history\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Check actual column names (they might be lowercase)\n",
    "    subject_col = 'subject_id' if 'subject_id' in df.columns else 'SUBJECT_ID'\n",
    "    hadm_col = 'hadm_id' if 'hadm_id' in df.columns else 'HADM_ID'\n",
    "    admit_col = 'ADMITTIME' if 'ADMITTIME' in df.columns else 'admittime'\n",
    "    \n",
    "    # Sort by patient and admission time to get chronological order\n",
    "    if admit_col in df.columns:\n",
    "        df[admit_col] = pd.to_datetime(df[admit_col])\n",
    "        df = df.sort_values([subject_col, admit_col])\n",
    "    else:\n",
    "        df = df.sort_values([subject_col, hadm_col])\n",
    "    \n",
    "    # --- Feature 1: Previous ICU stays for this patient ---\n",
    "    df['n_previous_icu_stays'] = df.groupby(subject_col).cumcount()\n",
    "    \n",
    "    # --- Feature 2: Is this the patient's first ICU visit? ---\n",
    "    df['is_first_icu_visit'] = (df['n_previous_icu_stays'] == 0).astype(int)\n",
    "    \n",
    "    # --- Feature 3: Previous hospital admissions ---\n",
    "    # Count unique HADM_IDs before current row for each patient\n",
    "    df['n_previous_admissions'] = df.groupby(subject_col)[hadm_col].transform(\n",
    "        lambda x: pd.Series(range(len(x)), index=x.index).map(\n",
    "            lambda i: x.iloc[:i].nunique() if i > 0 else 0\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # --- Feature 4: Time since last admission (if applicable) ---\n",
    "    if admit_col in df.columns:\n",
    "        df['days_since_last_admission'] = df.groupby(subject_col)[admit_col].diff().dt.total_seconds() / (24*3600)\n",
    "        df['days_since_last_admission'] = df['days_since_last_admission'].fillna(-1)  # -1 for first visit\n",
    "    \n",
    "    # --- Feature 5: Frequent flyer indicator ---\n",
    "    # Patients with 3+ ICU stays in dataset are high risk\n",
    "    icu_counts = df.groupby(subject_col).size()\n",
    "    frequent_flyers = icu_counts[icu_counts >= 3].index\n",
    "    df['is_frequent_flyer'] = df[subject_col].isin(frequent_flyers).astype(int)\n",
    "    \n",
    "    print(f\"\\n  âœ“ Created history features:\")\n",
    "    print(f\"    - n_previous_icu_stays (mean: {df['n_previous_icu_stays'].mean():.2f})\")\n",
    "    print(f\"    - is_first_icu_visit ({df['is_first_icu_visit'].sum()} first visits)\")\n",
    "    print(f\"    - n_previous_admissions (mean: {df['n_previous_admissions'].mean():.2f})\")\n",
    "    if 'days_since_last_admission' in df.columns:\n",
    "        valid_days = df[df['days_since_last_admission'] >= 0]['days_since_last_admission']\n",
    "        if len(valid_days) > 0:\n",
    "            print(f\"    - days_since_last_admission (median: {valid_days.median():.1f} days)\")\n",
    "    print(f\"    - is_frequent_flyer ({df['is_frequent_flyer'].sum()} frequent flyers)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create history features for train and test\n",
    "train = create_history_features(train)\n",
    "test = create_history_features(test)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. CREATE ICD9 DIAGNOSIS FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING ICD9 DIAGNOSIS FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check column names in diagnoses file (might also be lowercase)\n",
    "if 'HADM_ID' not in diagnoses.columns and 'hadm_id' in diagnoses.columns:\n",
    "    diagnoses.columns = diagnoses.columns.str.upper()\n",
    "\n",
    "# Now use consistent column names\n",
    "hadm_col = 'hadm_id' if 'hadm_id' in train.columns else 'HADM_ID'\n",
    "diagnoses_hadm_col = 'HADM_ID' if 'HADM_ID' in diagnoses.columns else 'hadm_id'\n",
    "\n",
    "# --- Feature 1: Number of diagnoses per admission ---\n",
    "n_diagnoses = diagnoses.groupby(diagnoses_hadm_col).size().to_dict()\n",
    "train['n_diagnoses'] = train[hadm_col].map(n_diagnoses).fillna(0)\n",
    "test['n_diagnoses'] = test[hadm_col].map(n_diagnoses).fillna(0)\n",
    "\n",
    "print(f\"\\n  âœ“ n_diagnoses (mean: {train['n_diagnoses'].mean():.1f})\")\n",
    "\n",
    "# --- Feature 2: Primary diagnosis (SEQ_NUM = 1) ---\n",
    "seq_col = 'SEQ_NUM' if 'SEQ_NUM' in diagnoses.columns else 'seq_num'\n",
    "icd_col = 'ICD9_CODE' if 'ICD9_CODE' in diagnoses.columns else 'icd9_code'\n",
    "\n",
    "primary_diagnoses = diagnoses[diagnoses[seq_col] == 1].set_index(diagnoses_hadm_col)[icd_col]\n",
    "train['primary_diagnosis'] = train[hadm_col].map(primary_diagnoses)\n",
    "test['primary_diagnosis'] = test[hadm_col].map(primary_diagnoses)\n",
    "\n",
    "print(f\"  âœ“ primary_diagnosis ({train['primary_diagnosis'].notna().sum()} found)\")\n",
    "\n",
    "# --- Feature 3: Extract category (first 3 digits) ---\n",
    "def extract_icd9_category(code):\n",
    "    if pd.isna(code):\n",
    "        return 'UNKNOWN'\n",
    "    code_str = str(code).strip().replace('.', '')\n",
    "    if len(code_str) >= 3:\n",
    "        return code_str[:3]\n",
    "    elif len(code_str) > 0:\n",
    "        return code_str\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "train['primary_diag_category'] = train['primary_diagnosis'].apply(extract_icd9_category)\n",
    "test['primary_diag_category'] = test['primary_diagnosis'].apply(extract_icd9_category)\n",
    "\n",
    "print(f\"  âœ“ primary_diag_category ({train['primary_diag_category'].nunique()} categories)\")\n",
    "\n",
    "# --- Feature 4: Major disease categories ---\n",
    "def get_major_category(code):\n",
    "    if pd.isna(code):\n",
    "        return 'UNKNOWN'\n",
    "    code_str = str(code).strip().replace('.', '')\n",
    "    if len(code_str) == 0:\n",
    "        return 'UNKNOWN'\n",
    "    \n",
    "    first_digit = code_str[0]\n",
    "    \n",
    "    if first_digit in ['0', '1']:\n",
    "        return 'INFECTIOUS'\n",
    "    elif first_digit == '2':\n",
    "        return 'NEOPLASM'\n",
    "    elif first_digit == '3':\n",
    "        return 'ENDOCRINE'\n",
    "    elif first_digit == '4':\n",
    "        return 'BLOOD'\n",
    "    elif first_digit == '5':\n",
    "        return 'MENTAL'\n",
    "    elif first_digit in ['6', '7']:\n",
    "        return 'NERVOUS'\n",
    "    elif first_digit == '8':\n",
    "        return 'CIRCULATORY'\n",
    "    elif first_digit == '9':\n",
    "        return 'RESPIRATORY'\n",
    "    elif first_digit == 'V' or first_digit == 'E':\n",
    "        return 'EXTERNAL'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "train['primary_major_category'] = train['primary_diagnosis'].apply(get_major_category)\n",
    "test['primary_major_category'] = test['primary_diagnosis'].apply(get_major_category)\n",
    "\n",
    "print(f\"  âœ“ primary_major_category:\")\n",
    "for cat, count in train['primary_major_category'].value_counts().head().items():\n",
    "    print(f\"    {cat}: {count} ({count/len(train)*100:.1f}%)\")\n",
    "\n",
    "# --- Feature 5: Condition flags ---\n",
    "print(\"\\n  Creating condition flags...\")\n",
    "\n",
    "hadm_diagnoses = diagnoses.groupby(diagnoses_hadm_col)[icd_col].apply(lambda x: set(x.astype(str)))\n",
    "\n",
    "def check_conditions(hadm_id):\n",
    "    if hadm_id not in hadm_diagnoses.index:\n",
    "        return {\n",
    "            'has_sepsis': 0,\n",
    "            'has_heart_failure': 0,\n",
    "            'has_resp_failure': 0,\n",
    "            'has_aki': 0,\n",
    "            'has_diabetes_comp': 0\n",
    "        }\n",
    "    \n",
    "    codes = hadm_diagnoses[hadm_id]\n",
    "    \n",
    "    return {\n",
    "        'has_sepsis': int(any(c.startswith(('99591', '99592', '78552')) for c in codes)),\n",
    "        'has_heart_failure': int(any(c.startswith('428') for c in codes)),\n",
    "        'has_resp_failure': int(any(c.startswith('518') for c in codes)),\n",
    "        'has_aki': int(any(c.startswith('584') for c in codes)),\n",
    "        'has_diabetes_comp': int(any(c.startswith('250') for c in codes))\n",
    "    }\n",
    "\n",
    "# Apply to train\n",
    "condition_flags_train = train[hadm_col].apply(check_conditions).apply(pd.Series)\n",
    "train = pd.concat([train, condition_flags_train], axis=1)\n",
    "\n",
    "# Apply to test\n",
    "condition_flags_test = test[hadm_col].apply(check_conditions).apply(pd.Series)\n",
    "test = pd.concat([test, condition_flags_test], axis=1)\n",
    "\n",
    "print(f\"  âœ“ Condition flags:\")\n",
    "for col in ['has_sepsis', 'has_heart_failure', 'has_resp_failure', 'has_aki', 'has_diabetes_comp']:\n",
    "    count = train[col].sum()\n",
    "    print(f\"    {col}: {count} ({count/len(train)*100:.1f}%)\")\n",
    "    \n",
    "# =============================================================================\n",
    "# 4. NOW CONTINUE WITH REGULAR PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STANDARD PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Drop leakage columns (but keep subject_id, hadm_id for now)\n",
    "columns_to_drop = [\n",
    "    'DISCHTIME', 'DEATHTIME', 'DOD', 'LOS',\n",
    "    'ADMITTIME', 'Diff',\n",
    "    'icustay_id',  # Drop after using it\n",
    "    'primary_diagnosis'  # Drop the raw diagnosis, keep encoded versions\n",
    "]\n",
    "\n",
    "train_clean = train.drop(columns=[c for c in columns_to_drop if c in train.columns], errors='ignore')\n",
    "test_clean = test.drop(columns=[c for c in columns_to_drop if c in test.columns], errors='ignore')\n",
    "\n",
    "# Separate target\n",
    "y = train_clean['HOSPITAL_EXPIRE_FLAG']\n",
    "X = train_clean.drop('HOSPITAL_EXPIRE_FLAG', axis=1)\n",
    "X_test = test_clean.copy()\n",
    "\n",
    "# Now we can drop IDs (we've used them for feature engineering)\n",
    "X = X.drop(['SUBJECT_ID', 'HADM_ID'], axis=1, errors='ignore')\n",
    "X_test = X_test.drop(['SUBJECT_ID', 'HADM_ID'], axis=1, errors='ignore')\n",
    "\n",
    "print(f\"\\nAfter ID removal: {X.shape[1]} features\")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric: {len(numeric_features)}, Categorical: {len(categorical_features)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. IMPUTATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Imputation ---\")\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "X[numeric_features] = numeric_imputer.fit_transform(X[numeric_features])\n",
    "X_test[numeric_features] = numeric_imputer.transform(X_test[numeric_features])\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X[categorical_features] = categorical_imputer.fit_transform(X[categorical_features])\n",
    "X_test[categorical_features] = categorical_imputer.transform(X_test[categorical_features])\n",
    "\n",
    "print(\"âœ“ Imputation complete\")\n",
    "\n",
    "# =============================================================================\n",
    "# 6. HANDLE DOB â†’ age\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Converting DOB to age ---\")\n",
    "\n",
    "if 'DOB' in categorical_features:\n",
    "    train_original = pd.read_csv(data_path / 'mimic_train_HEF.csv')\n",
    "    test_original = pd.read_csv(data_path / 'mimic_test_HEF.csv')\n",
    "    \n",
    "    dob_train = pd.to_datetime(X['DOB'], errors='coerce')\n",
    "    dob_test = pd.to_datetime(X_test['DOB'], errors='coerce')\n",
    "    admit_train = pd.to_datetime(train_original['ADMITTIME'], errors='coerce')\n",
    "    admit_test = pd.to_datetime(test_original['ADMITTIME'], errors='coerce')\n",
    "    \n",
    "    def calculate_age(admit_time, dob):\n",
    "        if pd.isna(admit_time) or pd.isna(dob):\n",
    "            return np.nan\n",
    "        try:\n",
    "            age_days = (admit_time - dob).days\n",
    "            age_years = age_days / 365.25\n",
    "            return age_years\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    X['age'] = [calculate_age(admit, dob) for admit, dob in zip(admit_train, dob_train)]\n",
    "    X_test['age'] = [calculate_age(admit, dob) for admit, dob in zip(admit_test, dob_test)]\n",
    "    \n",
    "    X['age'] = pd.to_numeric(X['age'], errors='coerce')\n",
    "    X_test['age'] = pd.to_numeric(X_test['age'], errors='coerce')\n",
    "    \n",
    "    X.loc[(X['age'] < 0) | (X['age'] > 120), 'age'] = np.nan\n",
    "    X_test.loc[(X_test['age'] < 0) | (X_test['age'] > 120), 'age'] = np.nan\n",
    "    \n",
    "    age_median = X['age'].median()\n",
    "    X['age'].fillna(age_median, inplace=True)\n",
    "    X_test['age'].fillna(age_median, inplace=True)\n",
    "    \n",
    "    X = X.drop('DOB', axis=1)\n",
    "    X_test = X_test.drop('DOB', axis=1)\n",
    "    categorical_features.remove('DOB')\n",
    "    numeric_features.append('age')\n",
    "    \n",
    "    print(f\"âœ“ Age: {X['age'].min():.1f} - {X['age'].max():.1f} years\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. TARGET ENCODE primary_diag_category (PROPERLY!)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Target encoding primary diagnosis ---\")\n",
    "\n",
    "if 'primary_diag_category' in X.columns:\n",
    "    # Target encode using mortality rate per category\n",
    "    encoding_map = y.groupby(X['primary_diag_category']).mean().to_dict()\n",
    "    global_mean = y.mean()\n",
    "    \n",
    "    X['primary_diag_encoded'] = X['primary_diag_category'].map(encoding_map)\n",
    "    X_test['primary_diag_encoded'] = X_test['primary_diag_category'].map(encoding_map).fillna(global_mean)\n",
    "    \n",
    "    numeric_features.append('primary_diag_encoded')\n",
    "    \n",
    "    X = X.drop('primary_diag_category', axis=1)\n",
    "    X_test = X_test.drop('primary_diag_category', axis=1)\n",
    "    categorical_features.remove('primary_diag_category')\n",
    "    \n",
    "    print(f\"âœ“ Primary diagnosis encoded (mortality rates: {X['primary_diag_encoded'].min():.3f} - {X['primary_diag_encoded'].max():.3f})\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. HANDLE OTHER CATEGORICALS (same as before)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Processing categorical features ---\")\n",
    "\n",
    "# ICD9_diagnosis (from original data)\n",
    "if 'ICD9_diagnosis' in X.columns:\n",
    "    def extract_icd9_category(code):\n",
    "        if pd.isna(code):\n",
    "            return 'UNKNOWN'\n",
    "        code_str = str(code).strip().replace('.', '')\n",
    "        if len(code_str) >= 3:\n",
    "            return code_str[:3]\n",
    "        elif len(code_str) > 0:\n",
    "            return code_str\n",
    "        else:\n",
    "            return 'UNKNOWN'\n",
    "    \n",
    "    X['ICD9_category'] = X['ICD9_diagnosis'].apply(extract_icd9_category)\n",
    "    X_test['ICD9_category'] = X_test['ICD9_diagnosis'].apply(extract_icd9_category)\n",
    "    \n",
    "    encoding_map = y.groupby(X['ICD9_category']).mean().to_dict()\n",
    "    \n",
    "    X['ICD9_encoded'] = X['ICD9_category'].map(encoding_map)\n",
    "    X_test['ICD9_encoded'] = X_test['ICD9_category'].map(encoding_map).fillna(global_mean)\n",
    "    \n",
    "    numeric_features.append('ICD9_encoded')\n",
    "    \n",
    "    X = X.drop(['ICD9_diagnosis', 'ICD9_category'], axis=1)\n",
    "    X_test = X_test.drop(['ICD9_diagnosis', 'ICD9_category'], axis=1)\n",
    "    categorical_features.remove('ICD9_diagnosis')\n",
    "    \n",
    "    print(\"âœ“ ICD9_diagnosis encoded\")\n",
    "\n",
    "# Drop DIAGNOSIS (free text)\n",
    "if 'DIAGNOSIS' in categorical_features:\n",
    "    X = X.drop('DIAGNOSIS', axis=1)\n",
    "    X_test = X_test.drop('DIAGNOSIS', axis=1)\n",
    "    categorical_features.remove('DIAGNOSIS')\n",
    "\n",
    "# Group ethnicity\n",
    "if 'ETHNICITY' in categorical_features:\n",
    "    def group_ethnicity(ethnicity):\n",
    "        if pd.isna(ethnicity):\n",
    "            return 'UNKNOWN'\n",
    "        ethnicity = str(ethnicity).upper()\n",
    "        if 'WHITE' in ethnicity:\n",
    "            return 'WHITE'\n",
    "        elif 'BLACK' in ethnicity or 'AFRICAN' in ethnicity:\n",
    "            return 'BLACK'\n",
    "        elif 'HISPANIC' in ethnicity or 'LATINO' in ethnicity:\n",
    "            return 'HISPANIC'\n",
    "        elif 'ASIAN' in ethnicity:\n",
    "            return 'ASIAN'\n",
    "        elif 'AMERICAN INDIAN' in ethnicity or 'ALASKA NATIVE' in ethnicity:\n",
    "            return 'NATIVE'\n",
    "        elif 'HAWAIIAN' in ethnicity or 'PACIFIC ISLANDER' in ethnicity:\n",
    "            return 'PACIFIC_ISLANDER'\n",
    "        elif any(x in ethnicity for x in ['UNKNOWN', 'UNABLE', 'DECLINED', 'NOT SPECIFIED']):\n",
    "            return 'UNKNOWN'\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    X['ETHNICITY'] = X['ETHNICITY'].apply(group_ethnicity)\n",
    "    X_test['ETHNICITY'] = X_test['ETHNICITY'].apply(group_ethnicity)\n",
    "\n",
    "# Group religion\n",
    "if 'RELIGION' in categorical_features:\n",
    "    def group_religion(religion):\n",
    "        if pd.isna(religion):\n",
    "            return 'UNKNOWN'\n",
    "        religion = str(religion).upper()\n",
    "        if 'CATHOLIC' in religion:\n",
    "            return 'CATHOLIC'\n",
    "        elif any(x in religion for x in ['PROTESTANT', 'EPISCOPALIAN', 'QUAKER']):\n",
    "            return 'PROTESTANT'\n",
    "        elif 'JEWISH' in religion or 'HEBREW' in religion:\n",
    "            return 'JEWISH'\n",
    "        elif 'MUSLIM' in religion:\n",
    "            return 'MUSLIM'\n",
    "        elif 'ORTHODOX' in religion:\n",
    "            return 'ORTHODOX'\n",
    "        elif any(x in religion for x in ['BUDDHIST', 'HINDU', 'JEHOVAH', 'CHRISTIAN SCIENTIST', \n",
    "                                          '7TH DAY ADVENTIST', 'UNITARIAN']):\n",
    "            return 'OTHER_RELIGION'\n",
    "        elif any(x in religion for x in ['UNOBTAINABLE', 'NOT SPECIFIED', 'UNKNOWN']):\n",
    "            return 'UNKNOWN'\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    X['RELIGION'] = X['RELIGION'].apply(group_religion)\n",
    "    X_test['RELIGION'] = X_test['RELIGION'].apply(group_religion)\n",
    "\n",
    "# Group marital status\n",
    "if 'MARITAL_STATUS' in categorical_features:\n",
    "    def group_marital_status(status):\n",
    "        if pd.isna(status):\n",
    "            return 'UNKNOWN'\n",
    "        status = str(status).upper()\n",
    "        if 'MARRIED' in status or 'LIFE PARTNER' in status:\n",
    "            return 'MARRIED'\n",
    "        elif 'SINGLE' in status:\n",
    "            return 'SINGLE'\n",
    "        elif 'WIDOWED' in status:\n",
    "            return 'WIDOWED'\n",
    "        elif 'DIVORCED' in status or 'SEPARATED' in status:\n",
    "            return 'DIVORCED_SEPARATED'\n",
    "        elif 'UNKNOWN' in status:\n",
    "            return 'UNKNOWN'\n",
    "        else:\n",
    "            return 'UNKNOWN'\n",
    "    \n",
    "    X['MARITAL_STATUS'] = X['MARITAL_STATUS'].apply(group_marital_status)\n",
    "    X_test['MARITAL_STATUS'] = X_test['MARITAL_STATUS'].apply(group_marital_status)\n",
    "\n",
    "# One-hot encode major category\n",
    "if 'primary_major_category' in X.columns:\n",
    "    X_combined = pd.concat([X, X_test], keys=['train', 'test'])\n",
    "    X_encoded = pd.get_dummies(X_combined, columns=['primary_major_category'], drop_first=True, prefix='diag')\n",
    "    X = X_encoded.xs('train')\n",
    "    X_test = X_encoded.xs('test')\n",
    "\n",
    "# One-hot encode remaining\n",
    "remaining_categorical = [col for col in categorical_features if col in X.columns]\n",
    "\n",
    "if len(remaining_categorical) > 0:\n",
    "    X_combined = pd.concat([X, X_test], keys=['train', 'test'])\n",
    "    X_encoded = pd.get_dummies(X_combined, columns=remaining_categorical, drop_first=True)\n",
    "    X = X_encoded.xs('train')\n",
    "    X_test = X_encoded.xs('test')\n",
    "\n",
    "print(f\"âœ“ Categorical encoding complete\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. FEATURE ENGINEERING (same as before - vitals-based)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Feature engineering (vitals) ---\")\n",
    "\n",
    "original_features = X.shape[1]\n",
    "\n",
    "# Blood pressure\n",
    "if all(col in X.columns for col in ['SysBP_Mean', 'DiasBP_Mean']):\n",
    "    X['PulsePressure'] = X['SysBP_Mean'] - X['DiasBP_Mean']\n",
    "    X_test['PulsePressure'] = X_test['SysBP_Mean'] - X_test['DiasBP_Mean']\n",
    "\n",
    "if all(col in X.columns for col in ['SysBP_Min', 'SysBP_Max']):\n",
    "    X['SysBP_Range'] = X['SysBP_Max'] - X['SysBP_Min']\n",
    "    X_test['SysBP_Range'] = X_test['SysBP_Max'] - X_test['SysBP_Min']\n",
    "\n",
    "# Shock indices\n",
    "if all(col in X.columns for col in ['HeartRate_Mean', 'SysBP_Mean']):\n",
    "    X['ShockIndex'] = (X['HeartRate_Mean'] / (X['SysBP_Mean'] + 1)).clip(0, 3)\n",
    "    X_test['ShockIndex'] = (X_test['HeartRate_Mean'] / (X_test['SysBP_Mean'] + 1)).clip(0, 3)\n",
    "\n",
    "if all(col in X.columns for col in ['HeartRate_Mean', 'MeanBP_Mean']):\n",
    "    X['ModifiedShockIndex'] = (X['HeartRate_Mean'] / (X['MeanBP_Mean'] + 1)).clip(0, 3)\n",
    "    X_test['ModifiedShockIndex'] = (X_test['HeartRate_Mean'] / (X_test['MeanBP_Mean'] + 1)).clip(0, 3)\n",
    "\n",
    "# Respiratory\n",
    "if 'SpO2_Min' in X.columns:\n",
    "    X['Hypoxemia'] = (X['SpO2_Min'] < 90).astype(int)\n",
    "    X_test['Hypoxemia'] = (X_test['SpO2_Min'] < 90).astype(int)\n",
    "\n",
    "if 'RespRate_Mean' in X.columns:\n",
    "    X['RespRate_Abnormal'] = ((X['RespRate_Mean'] < 12) | (X['RespRate_Mean'] > 20)).astype(int)\n",
    "    X_test['RespRate_Abnormal'] = ((X_test['RespRate_Mean'] < 12) | (X_test['RespRate_Mean'] > 20)).astype(int)\n",
    "\n",
    "# Temperature\n",
    "if 'TempC_Max' in X.columns:\n",
    "    X['Fever'] = (X['TempC_Max'] > 38).astype(int)\n",
    "    X_test['Fever'] = (X_test['TempC_Max'] > 38).astype(int)\n",
    "\n",
    "if 'TempC_Min' in X.columns:\n",
    "    X['Hypothermia'] = (X['TempC_Min'] < 36).astype(int)\n",
    "    X_test['Hypothermia'] = (X_test['TempC_Min'] < 36).astype(int)\n",
    "\n",
    "if all(col in X.columns for col in ['TempC_Min', 'TempC_Max']):\n",
    "    X['Temp_Range'] = X['TempC_Max'] - X['TempC_Min']\n",
    "    X_test['Temp_Range'] = X_test['TempC_Max'] - X_test['TempC_Min']\n",
    "\n",
    "# Glucose\n",
    "if 'Glucose_Max' in X.columns:\n",
    "    X['Hyperglycemia'] = (X['Glucose_Max'] > 180).astype(int)\n",
    "    X_test['Hyperglycemia'] = (X_test['Glucose_Max'] > 180).astype(int)\n",
    "\n",
    "if 'Glucose_Min' in X.columns:\n",
    "    X['Hypoglycemia'] = (X['Glucose_Min'] < 70).astype(int)\n",
    "    X_test['Hypoglycemia'] = (X_test['Glucose_Min'] < 70).astype(int)\n",
    "\n",
    "if all(col in X.columns for col in ['Glucose_Min', 'Glucose_Max']):\n",
    "    X['Glucose_Range'] = X['Glucose_Max'] - X['Glucose_Min']\n",
    "    X_test['Glucose_Range'] = X_test['Glucose_Max'] - X_test['Glucose_Min']\n",
    "\n",
    "# Age\n",
    "if 'age' in X.columns:\n",
    "    X['Elderly'] = (X['age'] > 65).astype(int)\n",
    "    X_test['Elderly'] = (X_test['age'] > 65).astype(int)\n",
    "    \n",
    "    X['age_squared'] = X['age'] ** 2\n",
    "    X_test['age_squared'] = X_test['age'] ** 2\n",
    "    \n",
    "    # TA hint: more age features!\n",
    "    X['age_risk_group'] = pd.cut(X['age'], \n",
    "                                   bins=[0, 18, 45, 65, 80, 120],\n",
    "                                   labels=['pediatric', 'young_adult', 'middle_age', 'elderly', 'very_old'])\n",
    "    X_test['age_risk_group'] = pd.cut(X_test['age'],\n",
    "                                        bins=[0, 18, 45, 65, 80, 120],\n",
    "                                        labels=['pediatric', 'young_adult', 'middle_age', 'elderly', 'very_old'])\n",
    "    \n",
    "    # One-hot encode age groups\n",
    "    X = pd.get_dummies(X, columns=['age_risk_group'], drop_first=True, prefix='age')\n",
    "    X_test = pd.get_dummies(X_test, columns=['age_risk_group'], drop_first=True, prefix='age')\n",
    "\n",
    "# Heart rate\n",
    "if all(col in X.columns for col in ['HeartRate_Min', 'HeartRate_Max']):\n",
    "    X['HeartRate_Range'] = X['HeartRate_Max'] - X['HeartRate_Min']\n",
    "    X_test['HeartRate_Range'] = X_test['HeartRate_Max'] - X_test['HeartRate_Min']\n",
    "\n",
    "# Severity score\n",
    "severity_components = []\n",
    "if 'ShockIndex' in X.columns:\n",
    "    severity_components.append((X['ShockIndex'] > 0.9).astype(int))\n",
    "if 'Hypoxemia' in X.columns:\n",
    "    severity_components.append(X['Hypoxemia'])\n",
    "if 'RespRate_Abnormal' in X.columns:\n",
    "    severity_components.append(X['RespRate_Abnormal'])\n",
    "if 'Fever' in X.columns:\n",
    "    severity_components.append(X['Fever'])\n",
    "if 'Hypothermia' in X.columns:\n",
    "    severity_components.append(X['Hypothermia'])\n",
    "\n",
    "if severity_components:\n",
    "    X['Severity_Score'] = sum(severity_components)\n",
    "    severity_components_test = []\n",
    "if 'ShockIndex' in X_test.columns:\n",
    "    severity_components_test.append((X_test['ShockIndex'] > 0.9).astype(int))\n",
    "if 'Hypoxemia' in X_test.columns:\n",
    "    severity_components_test.append(X_test['Hypoxemia'])\n",
    "if 'RespRate_Abnormal' in X_test.columns:\n",
    "    severity_components_test.append(X_test['RespRate_Abnormal'])\n",
    "if 'Fever' in X_test.columns:\n",
    "    severity_components_test.append(X_test['Fever'])\n",
    "if 'Hypothermia' in X_test.columns:\n",
    "    severity_components_test.append(X_test['Hypothermia'])\n",
    "\n",
    "X_test['Severity_Score'] = sum(severity_components_test)\n",
    "print(f\"âœ“ Added {X.shape[1] - original_features} engineered features\")\n",
    "#=============================================================================\n",
    "#10. SCALING\n",
    "#=============================================================================\n",
    "print(\"\\n--- Scaling ---\")\n",
    "all_numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "binary_features = [\n",
    "'Hypoxemia', 'RespRate_Abnormal', 'Fever', 'Hypothermia',\n",
    "'Hyperglycemia', 'Hypoglycemia', 'Elderly',\n",
    "'is_first_icu_visit', 'is_frequent_flyer',\n",
    "'has_sepsis', 'has_heart_failure', 'has_resp_failure', 'has_aki', 'has_diabetes_comp'\n",
    "]\n",
    "one_hot_features = [col for col in X.columns if ('_' in col and X[col].nunique() <= 2)]\n",
    "exclude_from_scaling = binary_features + one_hot_features\n",
    "features_to_scale = [col for col in all_numeric_cols if col not in exclude_from_scaling]\n",
    "scaler = StandardScaler()\n",
    "X[features_to_scale] = scaler.fit_transform(X[features_to_scale])\n",
    "X_test[features_to_scale] = scaler.transform(X_test[features_to_scale])\n",
    "print(f\"âœ“ Scaled {len(features_to_scale)} continuous features\")\n",
    "print(f\"âœ“ Left {len(exclude_from_scaling)} binary features unscaled\")\n",
    "#=============================================================================\n",
    "#11. SAVE\n",
    "#=============================================================================\n",
    "print(\"\\n--- Saving ---\")\n",
    "import os\n",
    "os.makedirs('../data/processed_enhanced', exist_ok=True)\n",
    "X.to_pickle('../data/processed_enhanced/X_train_processed.pkl')\n",
    "y.to_pickle('../data/processed_enhanced/y_train.pkl')\n",
    "X_test.to_pickle('../data/processed_enhanced/X_test_processed.pkl')\n",
    "test_ids.to_pickle('../data/processed_enhanced/test_ids.pkl')\n",
    "with open('../data/processed_enhanced/numeric_imputer.pkl', 'wb') as f:\n",
    "    pickle.dump(numeric_imputer, f)\n",
    "with open('../data/processed_enhanced/categorical_imputer.pkl', 'wb') as f:\n",
    "    pickle.dump(categorical_imputer, f)\n",
    "with open('../data/processed_enhanced/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"âœ“ Saved to ../data/processed_enhanced/\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nFinal feature count: {X.shape[1]}\")\n",
    "print(f\"  Original vitals: ~35\")\n",
    "print(f\"  Hospital history: ~5\")\n",
    "print(f\"  ICD9 diagnoses: ~6\")\n",
    "print(f\"  Condition flags: 5\")\n",
    "print(f\"  Engineered: ~20\")\n",
    "print(f\"  One-hot encoded: ~{X.shape[1] - 71}\")\n",
    "print(\"\\nðŸŽ¯ Ready to train models with enhanced features!\")\n",
    "print(\"   Expected improvement: significant boost from hospital history + diagnoses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbaac3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b95932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Saved 5221 test IDs for submission\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAVE TEST IDs FIRST (BEFORE DROPPING!)\n",
    "# =============================================================================\n",
    "\n",
    "test_ids = test['icustay_id'].copy()\n",
    "print(f\"\\nâœ“ Saved {len(test_ids)} test IDs for submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7e4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. DROP LEAKAGE COLUMNS\n",
    "# =============================================================================\n",
    "columns_to_drop = [\n",
    "    'DISCHTIME', 'DEATHTIME', 'DOD', 'LOS',\n",
    "    'subject_id', 'hadm_id', 'icustay_id',\n",
    "    'ADMITTIME', 'Diff'\n",
    "]\n",
    "\n",
    "train_clean = train.drop(columns=columns_to_drop, errors='ignore')\n",
    "test_clean = test.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599153bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. SEPARATE TARGET\n",
    "# =============================================================================\n",
    "y = train_clean['HOSPITAL_EXPIRE_FLAG']\n",
    "X = train_clean.drop('HOSPITAL_EXPIRE_FLAG', axis=1)\n",
    "X_test = test_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357cffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric features: 24\n",
      "Categorical features: 10\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4. IDENTIFY FEATURE TYPES\n",
    "# =============================================================================\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05dd99c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Imputing missing values ---\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. IMPUTATION\n",
    "# =============================================================================\n",
    "print(\"\\n--- Imputing missing values ---\")\n",
    "\n",
    "# Numeric\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "X[numeric_features] = numeric_imputer.fit_transform(X[numeric_features])\n",
    "X_test[numeric_features] = numeric_imputer.transform(X_test[numeric_features])\n",
    "\n",
    "# Categorical\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X[categorical_features] = categorical_imputer.fit_transform(X[categorical_features])\n",
    "X_test[categorical_features] = categorical_imputer.transform(X_test[categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d663e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1: Converting DOB to age ---\n",
      "  âœ“ Calculated age from DOB and ADMITTIME\n",
      "    Age range: 15.0 - 89.0 years\n",
      "    Mean age: 62.7 years\n",
      "    Missing ages: 1107\n",
      "    âœ“ Imputed invalid ages with median: 64.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\1596579972.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['age'].fillna(age_median, inplace=True)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\1596579972.py:68: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test['age'].fillna(age_median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# STEP 1: Convert DOB to age (handling MIMIC-III date shifting)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 1: Converting DOB to age ---\")\n",
    "\n",
    "if 'DOB' in X.columns and 'DOB' in categorical_features:\n",
    "    # MIMIC-III shifts all dates forward by ~200 years for anonymization\n",
    "    # But the RELATIVE age is preserved\n",
    "    # Strategy: Calculate age = ADMITTIME - DOB\n",
    "    \n",
    "    # Reload original data to get ADMITTIME\n",
    "    train_original = pd.read_csv('../data/mimic_train_HEF.csv')\n",
    "    test_original = pd.read_csv('../data/mimic_test_HEF.csv')\n",
    "    \n",
    "    # Convert to datetime\n",
    "    dob_train = pd.to_datetime(X['DOB'], errors='coerce')\n",
    "    dob_test = pd.to_datetime(X_test['DOB'], errors='coerce')\n",
    "    admit_train = pd.to_datetime(train_original['ADMITTIME'], errors='coerce')\n",
    "    admit_test = pd.to_datetime(test_original['ADMITTIME'], errors='coerce')\n",
    "    \n",
    "    # Calculate age using timedelta and convert to years\n",
    "    # Use .apply() to avoid overflow\n",
    "    def calculate_age(admit_time, dob):\n",
    "        if pd.isna(admit_time) or pd.isna(dob):\n",
    "            return np.nan\n",
    "        try:\n",
    "            # Calculate difference in days, then convert to years\n",
    "            age_days = (admit_time - dob).days\n",
    "            age_years = age_days / 365.25\n",
    "            return age_years\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    # Calculate age for train\n",
    "    X['age'] = [calculate_age(admit, dob) for admit, dob in zip(admit_train, dob_train)]\n",
    "    \n",
    "    # Calculate age for test\n",
    "    X_test['age'] = [calculate_age(admit, dob) for admit, dob in zip(admit_test, dob_test)]\n",
    "    \n",
    "    # Convert to numeric (in case of any issues)\n",
    "    X['age'] = pd.to_numeric(X['age'], errors='coerce')\n",
    "    X_test['age'] = pd.to_numeric(X_test['age'], errors='coerce')\n",
    "    \n",
    "    # Clean up\n",
    "    X = X.drop('DOB', axis=1)\n",
    "    X_test = X_test.drop('DOB', axis=1)\n",
    "    categorical_features.remove('DOB')\n",
    "    \n",
    "    print(f\"  âœ“ Calculated age from DOB and ADMITTIME\")\n",
    "    print(f\"    Age range: {X['age'].min():.1f} - {X['age'].max():.1f} years\")\n",
    "    print(f\"    Mean age: {X['age'].mean():.1f} years\")\n",
    "    print(f\"    Missing ages: {X['age'].isna().sum()}\")\n",
    "    \n",
    "    # Sanity check: ages should be reasonable (0-120 years)\n",
    "    if X['age'].max() > 120 or X['age'].min() < 0:\n",
    "        print(f\"    âš ï¸ WARNING: Unusual age range detected!\")\n",
    "        print(f\"    Sample ages: {X['age'].head(10).tolist()}\")\n",
    "    \n",
    "    # Handle missing or invalid ages\n",
    "    if X['age'].isna().sum() > 0 or (X['age'] < 0).any() or (X['age'] > 120).any():\n",
    "        # Set invalid ages to NaN\n",
    "        X.loc[(X['age'] < 0) | (X['age'] > 120), 'age'] = np.nan\n",
    "        X_test.loc[(X_test['age'] < 0) | (X_test['age'] > 120), 'age'] = np.nan\n",
    "        \n",
    "        # Impute with median\n",
    "        age_median = X['age'].median()\n",
    "        X['age'].fillna(age_median, inplace=True)\n",
    "        X_test['age'].fillna(age_median, inplace=True)\n",
    "        print(f\"    âœ“ Imputed invalid ages with median: {age_median:.1f}\")\n",
    "    \n",
    "    # Add to numeric features for scaling later\n",
    "    if 'age' not in numeric_features:\n",
    "        numeric_features.append('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ef4928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DIAGNOSING CATEGORICAL FEATURES\n",
      "======================================================================\n",
      "\n",
      "Total categorical features: 9\n",
      "  GENDER: 2 unique values\n",
      "    Distribution: {'M': 11759, 'F': 9126}\n",
      "  ADMISSION_TYPE: 3 unique values\n",
      "    Distribution: {'EMERGENCY': 17817, 'ELECTIVE': 2848, 'URGENT': 220}\n",
      "  INSURANCE: 5 unique values\n",
      "    Distribution: {'Medicare': 11718, 'Private': 6245, 'Medicaid': 2117, 'Government': 611, 'Self Pay': 194}\n",
      "  RELIGION: 17 unique values\n",
      "    âš ï¸ HIGH CARDINALITY - will create 17 one-hot columns!\n",
      "  MARITAL_STATUS: 7 unique values\n",
      "    Distribution: {'MARRIED': 10386, 'SINGLE': 5910, 'WIDOWED': 2819, 'DIVORCED': 1413, 'SEPARATED': 240, 'UNKNOWN (DEFAULT)': 103, 'LIFE PARTNER': 14}\n",
      "  ETHNICITY: 41 unique values\n",
      "    âš ï¸ HIGH CARDINALITY - will create 41 one-hot columns!\n",
      "  DIAGNOSIS: 6193 unique values\n",
      "    âš ï¸ HIGH CARDINALITY - will create 6193 one-hot columns!\n",
      "  ICD9_diagnosis: 1853 unique values\n",
      "    âš ï¸ HIGH CARDINALITY - will create 1853 one-hot columns!\n",
      "  FIRST_CAREUNIT: 5 unique values\n",
      "    Distribution: {'MICU': 8640, 'SICU': 3961, 'CSRU': 3127, 'TSICU': 2645, 'CCU': 2512}\n",
      "\n",
      "âš ï¸ ESTIMATED TOTAL FEATURES AFTER ONE-HOT ENCODING: 8142\n",
      "Current numeric features: 25\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5.5. DIAGNOSE HIGH-CARDINALITY CATEGORICAL FEATURES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIAGNOSING CATEGORICAL FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTotal categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# Check cardinality (number of unique values) for each categorical feature\n",
    "for cat_col in categorical_features:\n",
    "    n_unique = X[cat_col].nunique()\n",
    "    print(f\"  {cat_col}: {n_unique} unique values\")\n",
    "    \n",
    "    # Show distribution if few unique values\n",
    "    if n_unique <= 10:\n",
    "        print(f\"    Distribution: {X[cat_col].value_counts().to_dict()}\")\n",
    "    else:\n",
    "        print(f\"    âš ï¸ HIGH CARDINALITY - will create {n_unique} one-hot columns!\")\n",
    "\n",
    "# Estimate final feature count after one-hot encoding\n",
    "estimated_features = len(numeric_features)\n",
    "for cat_col in categorical_features:\n",
    "    estimated_features += X[cat_col].nunique() - 1  # -1 because drop_first=True\n",
    "\n",
    "print(f\"\\nâš ï¸ ESTIMATED TOTAL FEATURES AFTER ONE-HOT ENCODING: {estimated_features}\")\n",
    "print(f\"Current numeric features: {len(numeric_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95243011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SMART CATEGORICAL ENCODING\n",
      "======================================================================\n",
      "\n",
      "--- Step 2: Processing ICD9_diagnosis codes ---\n",
      "  âœ“ Extracted ICD9 categories: 530 unique categories\n",
      "  â†’ Using target encoding for ICD9 categories\n",
      "  âœ“ ICD9_diagnosis â†’ ICD9_encoded (numeric)\n",
      "\n",
      "--- Step 3: Processing DIAGNOSIS (free text) ---\n",
      "  âœ“ Dropping DIAGNOSIS (free text, 6193 unique values)\n",
      "    â†’ Keeping ICD9_encoded instead (more structured)\n",
      "\n",
      "--- Step 4: Grouping ETHNICITY ---\n",
      "  âœ“ Grouped ETHNICITY: 41 â†’ 8 categories\n",
      "    New categories: ['ASIAN', 'BLACK', 'HISPANIC', 'NATIVE', 'OTHER', 'PACIFIC_ISLANDER', 'UNKNOWN', 'WHITE']\n",
      "    Distribution:\n",
      "      WHITE: 15330 (73.4%)\n",
      "      BLACK: 2201 (10.5%)\n",
      "      UNKNOWN: 1320 (6.3%)\n",
      "      HISPANIC: 852 (4.1%)\n",
      "      OTHER: 616 (2.9%)\n",
      "      ASIAN: 545 (2.6%)\n",
      "      NATIVE: 15 (0.1%)\n",
      "      PACIFIC_ISLANDER: 6 (0.0%)\n",
      "\n",
      "--- Step 5: Grouping RELIGION ---\n",
      "  âœ“ Grouped RELIGION: 17 â†’ 8 categories\n",
      "    New categories: ['CATHOLIC', 'JEWISH', 'MUSLIM', 'ORTHODOX', 'OTHER', 'OTHER_RELIGION', 'PROTESTANT', 'UNKNOWN']\n",
      "    Distribution:\n",
      "      CATHOLIC: 7655 (36.7%)\n",
      "      UNKNOWN: 6913 (33.1%)\n",
      "      PROTESTANT: 3041 (14.6%)\n",
      "      JEWISH: 1841 (8.8%)\n",
      "      OTHER: 743 (3.6%)\n",
      "      OTHER_RELIGION: 440 (2.1%)\n",
      "      ORTHODOX: 178 (0.9%)\n",
      "      MUSLIM: 74 (0.4%)\n",
      "\n",
      "--- Step 6: Grouping MARITAL_STATUS ---\n",
      "  âœ“ Grouped MARITAL_STATUS: 7 â†’ 5 categories\n",
      "    New categories: ['DIVORCED_SEPARATED', 'MARRIED', 'SINGLE', 'UNKNOWN', 'WIDOWED']\n",
      "    Distribution:\n",
      "      MARRIED: 10400 (49.8%)\n",
      "      SINGLE: 5910 (28.3%)\n",
      "      WIDOWED: 2819 (13.5%)\n",
      "      DIVORCED_SEPARATED: 1653 (7.9%)\n",
      "      UNKNOWN: 103 (0.5%)\n",
      "\n",
      "--- Step 7: One-hot encoding remaining categorical features ---\n",
      "\n",
      "Features to one-hot encode (7):\n",
      "  GENDER: 2 categories â†’ 1 binary features\n",
      "  ADMISSION_TYPE: 3 categories â†’ 2 binary features\n",
      "  INSURANCE: 5 categories â†’ 4 binary features\n",
      "  RELIGION: 8 categories â†’ 7 binary features\n",
      "  MARITAL_STATUS: 5 categories â†’ 4 binary features\n",
      "  ETHNICITY: 8 categories â†’ 7 binary features\n",
      "  FIRST_CAREUNIT: 5 categories â†’ 4 binary features\n",
      "\n",
      "Estimated new binary features from one-hot encoding: 29\n",
      "âœ“ One-hot encoding complete\n",
      "\n",
      "======================================================================\n",
      "ENCODING COMPLETE - SUMMARY\n",
      "======================================================================\n",
      "Original numeric features: 26\n",
      "Target-encoded features: 1 (ICD9_encoded)\n",
      "Binary features from one-hot encoding: 29\n",
      "\n",
      "Final shapes:\n",
      "  X: (20885, 55)\n",
      "  X_test: (5221, 55)\n",
      "  Total features: 55\n",
      "\n",
      "âœ“ Feature count looks good (55 features)\n",
      "\n",
      "Sample of final features (first 20):\n",
      "['HeartRate_Min', 'HeartRate_Max', 'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min', 'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean', 'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min', 'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7. SMART CATEGORICAL ENCODING\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SMART CATEGORICAL ENCODING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 2: Handle ICD9_diagnosis (extract category, then target encode)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 2: Processing ICD9_diagnosis codes ---\")\n",
    "\n",
    "if 'ICD9_diagnosis' in X.columns:\n",
    "    # ICD9 codes have hierarchical structure:\n",
    "    # First digit = broad category (e.g., 4XX = circulatory system)\n",
    "    # First 3 digits = more specific category\n",
    "    \n",
    "    def extract_icd9_category(code):\n",
    "        \"\"\"Extract first 3 characters from ICD9 code\"\"\"\n",
    "        if pd.isna(code):\n",
    "            return 'UNKNOWN'\n",
    "        code_str = str(code).strip()\n",
    "        # Remove decimal point and take first 3 characters\n",
    "        code_str = code_str.replace('.', '')\n",
    "        if len(code_str) >= 3:\n",
    "            return code_str[:3]\n",
    "        elif len(code_str) > 0:\n",
    "            return code_str\n",
    "        else:\n",
    "            return 'UNKNOWN'\n",
    "    \n",
    "    X['ICD9_category'] = X['ICD9_diagnosis'].apply(extract_icd9_category)\n",
    "    X_test['ICD9_category'] = X_test['ICD9_diagnosis'].apply(extract_icd9_category)\n",
    "    \n",
    "    n_icd9_categories = X['ICD9_category'].nunique()\n",
    "    print(f\"  âœ“ Extracted ICD9 categories: {n_icd9_categories} unique categories\")\n",
    "    \n",
    "    # Target encode (because still likely 100+ categories)\n",
    "    print(f\"  â†’ Using target encoding for ICD9 categories\")\n",
    "    encoding_map = y.groupby(X['ICD9_category']).mean().to_dict()\n",
    "    global_mean = y.mean()\n",
    "    \n",
    "    X['ICD9_encoded'] = X['ICD9_category'].map(encoding_map)\n",
    "    X_test['ICD9_encoded'] = X_test['ICD9_category'].map(encoding_map).fillna(global_mean)\n",
    "    \n",
    "    # Add to numeric features (target encoding creates numeric feature)\n",
    "    numeric_features.append('ICD9_encoded')\n",
    "    \n",
    "    # Drop originals\n",
    "    X = X.drop(['ICD9_diagnosis', 'ICD9_category'], axis=1)\n",
    "    X_test = X_test.drop(['ICD9_diagnosis', 'ICD9_category'], axis=1)\n",
    "    categorical_features.remove('ICD9_diagnosis')\n",
    "    \n",
    "    print(f\"  âœ“ ICD9_diagnosis â†’ ICD9_encoded (numeric)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 3: Handle DIAGNOSIS (free text - extract keywords or drop)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 3: Processing DIAGNOSIS (free text) ---\")\n",
    "\n",
    "if 'DIAGNOSIS' in X.columns:\n",
    "    # Option 1: Drop it (safest - free text is very high cardinality)\n",
    "    # Option 2: Extract common keywords (more complex)\n",
    "    \n",
    "    # For now, let's DROP it to keep things simple\n",
    "    # (We already have ICD9 codes which are more structured)\n",
    "    \n",
    "    print(f\"  âœ“ Dropping DIAGNOSIS (free text, {X['DIAGNOSIS'].nunique()} unique values)\")\n",
    "    print(f\"    â†’ Keeping ICD9_encoded instead (more structured)\")\n",
    "    \n",
    "    X = X.drop('DIAGNOSIS', axis=1)\n",
    "    X_test = X_test.drop('DIAGNOSIS', axis=1)\n",
    "    categorical_features.remove('DIAGNOSIS')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 4: Group ETHNICITY into broader categories\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 4: Grouping ETHNICITY ---\")\n",
    "\n",
    "if 'ETHNICITY' in X.columns:\n",
    "    def group_ethnicity(ethnicity):\n",
    "        if pd.isna(ethnicity):\n",
    "            return 'UNKNOWN'\n",
    "        ethnicity = str(ethnicity).upper()\n",
    "        \n",
    "        # WHITE (includes variants like WHITE - RUSSIAN, WHITE - BRAZILIAN, etc.)\n",
    "        if 'WHITE' in ethnicity:\n",
    "            return 'WHITE'\n",
    "        \n",
    "        # BLACK (includes BLACK/AFRICAN AMERICAN, BLACK/HAITIAN, BLACK/CAPE VERDEAN, etc.)\n",
    "        elif 'BLACK' in ethnicity or 'AFRICAN' in ethnicity:\n",
    "            return 'BLACK'\n",
    "        \n",
    "        # HISPANIC/LATINO (all variants)\n",
    "        elif 'HISPANIC' in ethnicity or 'LATINO' in ethnicity:\n",
    "            return 'HISPANIC'\n",
    "        \n",
    "        # ASIAN (includes ASIAN - CHINESE, ASIAN - VIETNAMESE, etc.)\n",
    "        elif 'ASIAN' in ethnicity:\n",
    "            return 'ASIAN'\n",
    "        \n",
    "        # NATIVE/INDIGENOUS (American Indian/Alaska Native)\n",
    "        elif 'AMERICAN INDIAN' in ethnicity or 'ALASKA NATIVE' in ethnicity:\n",
    "            return 'NATIVE'\n",
    "        \n",
    "        # PACIFIC ISLANDER\n",
    "        elif 'HAWAIIAN' in ethnicity or 'PACIFIC ISLANDER' in ethnicity:\n",
    "            return 'PACIFIC_ISLANDER'\n",
    "        \n",
    "        # UNKNOWN/NOT SPECIFIED/DECLINED\n",
    "        elif any(x in ethnicity for x in ['UNKNOWN', 'UNABLE', 'DECLINED', 'NOT SPECIFIED']):\n",
    "            return 'UNKNOWN'\n",
    "        \n",
    "        # OTHER (includes MULTI RACE, MIDDLE EASTERN, CARIBBEAN, PORTUGUESE, etc.)\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    X['ETHNICITY'] = X['ETHNICITY'].apply(group_ethnicity)\n",
    "    X_test['ETHNICITY'] = X_test['ETHNICITY'].apply(group_ethnicity)\n",
    "    \n",
    "    print(f\"  âœ“ Grouped ETHNICITY: 41 â†’ {X['ETHNICITY'].nunique()} categories\")\n",
    "    print(f\"    New categories: {sorted(X['ETHNICITY'].unique())}\")\n",
    "    print(f\"    Distribution:\")\n",
    "    for cat, count in X['ETHNICITY'].value_counts().items():\n",
    "        print(f\"      {cat}: {count} ({count/len(X)*100:.1f}%)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 5: Group RELIGION into broader categories\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 5: Grouping RELIGION ---\")\n",
    "\n",
    "if 'RELIGION' in X.columns:\n",
    "    def group_religion(religion):\n",
    "        if pd.isna(religion):\n",
    "            return 'UNKNOWN'\n",
    "        religion = str(religion).upper()\n",
    "        \n",
    "        # CATHOLIC\n",
    "        if 'CATHOLIC' in religion:\n",
    "            return 'CATHOLIC'\n",
    "        \n",
    "        # PROTESTANT/CHRISTIAN (includes PROTESTANT QUAKER, EPISCOPALIAN, etc.)\n",
    "        elif any(x in religion for x in ['PROTESTANT', 'EPISCOPALIAN', 'QUAKER']):\n",
    "            return 'PROTESTANT'\n",
    "        \n",
    "        # JEWISH (includes HEBREW)\n",
    "        elif 'JEWISH' in religion or 'HEBREW' in religion:\n",
    "            return 'JEWISH'\n",
    "        \n",
    "        # MUSLIM\n",
    "        elif 'MUSLIM' in religion:\n",
    "            return 'MUSLIM'\n",
    "        \n",
    "        # ORTHODOX (GREEK ORTHODOX, ROMANIAN ORTHODOX)\n",
    "        elif 'ORTHODOX' in religion:\n",
    "            return 'ORTHODOX'\n",
    "        \n",
    "        # OTHER RELIGIONS (Buddhist, Hindu, Christian Scientist, Jehovah's Witness, etc.)\n",
    "        elif any(x in religion for x in ['BUDDHIST', 'HINDU', 'JEHOVAH', 'CHRISTIAN SCIENTIST', \n",
    "                                          '7TH DAY ADVENTIST', 'UNITARIAN']):\n",
    "            return 'OTHER_RELIGION'\n",
    "        \n",
    "        # UNKNOWN/NOT SPECIFIED\n",
    "        elif any(x in religion for x in ['UNOBTAINABLE', 'NOT SPECIFIED', 'UNKNOWN']):\n",
    "            return 'UNKNOWN'\n",
    "        \n",
    "        # OTHER\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    X['RELIGION'] = X['RELIGION'].apply(group_religion)\n",
    "    X_test['RELIGION'] = X_test['RELIGION'].apply(group_religion)\n",
    "    \n",
    "    print(f\"  âœ“ Grouped RELIGION: 17 â†’ {X['RELIGION'].nunique()} categories\")\n",
    "    print(f\"    New categories: {sorted(X['RELIGION'].unique())}\")\n",
    "    print(f\"    Distribution:\")\n",
    "    for cat, count in X['RELIGION'].value_counts().items():\n",
    "        print(f\"      {cat}: {count} ({count/len(X)*100:.1f}%)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 6: Group MARITAL_STATUS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 6: Grouping MARITAL_STATUS ---\")\n",
    "\n",
    "if 'MARITAL_STATUS' in X.columns:\n",
    "    def group_marital_status(status):\n",
    "        if pd.isna(status):\n",
    "            return 'UNKNOWN'\n",
    "        status = str(status).upper()\n",
    "        \n",
    "        # MARRIED (includes LIFE PARTNER)\n",
    "        if 'MARRIED' in status or 'LIFE PARTNER' in status:\n",
    "            return 'MARRIED'\n",
    "        \n",
    "        # SINGLE\n",
    "        elif 'SINGLE' in status:\n",
    "            return 'SINGLE'\n",
    "        \n",
    "        # WIDOWED\n",
    "        elif 'WIDOWED' in status:\n",
    "            return 'WIDOWED'\n",
    "        \n",
    "        # DIVORCED/SEPARATED (group together - both indicate ended relationship)\n",
    "        elif 'DIVORCED' in status or 'SEPARATED' in status:\n",
    "            return 'DIVORCED_SEPARATED'\n",
    "        \n",
    "        # UNKNOWN\n",
    "        elif 'UNKNOWN' in status:\n",
    "            return 'UNKNOWN'\n",
    "        \n",
    "        else:\n",
    "            return 'UNKNOWN'\n",
    "    \n",
    "    X['MARITAL_STATUS'] = X['MARITAL_STATUS'].apply(group_marital_status)\n",
    "    X_test['MARITAL_STATUS'] = X_test['MARITAL_STATUS'].apply(group_marital_status)\n",
    "    \n",
    "    print(f\"  âœ“ Grouped MARITAL_STATUS: 7 â†’ {X['MARITAL_STATUS'].nunique()} categories\")\n",
    "    print(f\"    New categories: {sorted(X['MARITAL_STATUS'].unique())}\")\n",
    "    print(f\"    Distribution:\")\n",
    "    for cat, count in X['MARITAL_STATUS'].value_counts().items():\n",
    "        print(f\"      {cat}: {count} ({count/len(X)*100:.1f}%)\")\n",
    "# -----------------------------------------------------------------------------\n",
    "# STEP 7: One-hot encode remaining low-cardinality features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 7: One-hot encoding remaining categorical features ---\")\n",
    "\n",
    "# Update categorical_features list\n",
    "remaining_categorical = [col for col in categorical_features if col in X.columns]\n",
    "print(f\"\\nFeatures to one-hot encode ({len(remaining_categorical)}):\")\n",
    "\n",
    "# Verify cardinality\n",
    "total_new_features = 0\n",
    "for col in remaining_categorical:\n",
    "    n_unique = X[col].nunique()\n",
    "    total_new_features += (n_unique - 1)  # drop_first=True\n",
    "    print(f\"  {col}: {n_unique} categories â†’ {n_unique-1} binary features\")\n",
    "\n",
    "print(f\"\\nEstimated new binary features from one-hot encoding: {total_new_features}\")\n",
    "\n",
    "if len(remaining_categorical) > 0:\n",
    "    # One-hot encode\n",
    "    X_combined = pd.concat([X, X_test], keys=['train', 'test'])\n",
    "    X_encoded = pd.get_dummies(X_combined, columns=remaining_categorical, drop_first=True)\n",
    "    X = X_encoded.xs('train')\n",
    "    X_test = X_encoded.xs('test')\n",
    "    \n",
    "    print(f\"âœ“ One-hot encoding complete\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# FINAL SUMMARY\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENCODING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Original numeric features: {len(numeric_features)}\")\n",
    "print(f\"Target-encoded features: 1 (ICD9_encoded)\")\n",
    "print(f\"Binary features from one-hot encoding: {total_new_features}\")\n",
    "print(f\"\\nFinal shapes:\")\n",
    "print(f\"  X: {X.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  Total features: {X.shape[1]}\")\n",
    "\n",
    "# Check if reasonable\n",
    "if X.shape[1] > 200:\n",
    "    print(f\"\\nâš ï¸ WARNING: {X.shape[1]} features might still be too many\")\n",
    "    print(\"Consider more aggressive grouping or feature selection\")\n",
    "elif X.shape[1] < 50:\n",
    "    print(f\"\\nâš ï¸ WARNING: Only {X.shape[1]} features - might be too few\")\n",
    "    print(\"Consider keeping more granular categories\")\n",
    "else:\n",
    "    print(f\"\\nâœ“ Feature count looks good ({X.shape[1]} features)\")\n",
    "\n",
    "# Show a sample of the final feature names\n",
    "print(f\"\\nSample of final features (first 20):\")\n",
    "print(list(X.columns[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca357bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRANSFORMING SKEWED FEATURES\n",
      "======================================================================\n",
      "\n",
      "--- Creating glucose indicators (before transformation) ---\n",
      "  âœ“ Hyperglycemia: 7537 cases (36.1%)\n",
      "  âœ“ Hypoglycemia: 1722 cases (8.2%)\n",
      "  âœ“ Log-transformed Glucose_Max\n",
      "  âœ“ Log-transformed Glucose_Mean\n",
      "  âœ“ Log-transformed Glucose_Min\n",
      "  âœ“ Log-transformed MeanBP_Max\n",
      "\n",
      "Transformed 4 skewed features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\1678635918.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hyperglycemia'] = (X['Glucose_Max'] > 180).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\1678635918.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hyperglycemia'] = (X_test['Glucose_Max'] > 180).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\1678635918.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hypoglycemia'] = (X['Glucose_Min'] < 70).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\1678635918.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hypoglycemia'] = (X_test['Glucose_Min'] < 70).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\1678635918.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feat] = np.log1p(X[feat] - X[feat].min() + 1)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\1678635918.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feat] = np.log1p(X_test[feat] - X_test[feat].min() + 1)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7.5. TRANSFORM SKEWED FEATURES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSFORMING SKEWED FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# FIRST: Create glucose binary indicators BEFORE transformation\n",
    "print(\"\\n--- Creating glucose indicators (before transformation) ---\")\n",
    "\n",
    "if 'Glucose_Max' in X.columns:\n",
    "    X['Hyperglycemia'] = (X['Glucose_Max'] > 180).astype(int)\n",
    "    X_test['Hyperglycemia'] = (X_test['Glucose_Max'] > 180).astype(int)\n",
    "    print(f\"  âœ“ Hyperglycemia: {X['Hyperglycemia'].sum()} cases ({X['Hyperglycemia'].mean()*100:.1f}%)\")\n",
    "\n",
    "if 'Glucose_Min' in X.columns:\n",
    "    X['Hypoglycemia'] = (X['Glucose_Min'] < 70).astype(int)\n",
    "    X_test['Hypoglycemia'] = (X_test['Glucose_Min'] < 70).astype(int)\n",
    "    print(f\"  âœ“ Hypoglycemia: {X['Hypoglycemia'].sum()} cases ({X['Hypoglycemia'].mean()*100:.1f}%)\")\n",
    "\n",
    "\n",
    "# Apply log transformation to highly skewed features\n",
    "# This helps models learn better from skewed distributions\n",
    "\n",
    "skewed_features_to_transform = [\n",
    "    'Glucose_Max', 'Glucose_Mean', 'Glucose_Min', 'Glucose_Range',\n",
    "    'MeanBP_Max', 'Temp_Range', 'age_squared'\n",
    "]\n",
    "\n",
    "for feat in skewed_features_to_transform:\n",
    "    if feat in X.columns:\n",
    "        # Add 1 to handle any zeros, then log transform\n",
    "        X[feat] = np.log1p(X[feat] - X[feat].min() + 1)\n",
    "        X_test[feat] = np.log1p(X_test[feat] - X_test[feat].min() + 1)\n",
    "        print(f\"  âœ“ Log-transformed {feat}\")\n",
    "\n",
    "print(f\"\\nTransformed {len([f for f in skewed_features_to_transform if f in X.columns])} skewed features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "308d0add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "--- Blood Pressure Features ---\n",
      "  âœ“ Pulse pressure\n",
      "  âœ“ Systolic BP range\n",
      "\n",
      "--- Shock Indices ---\n",
      "  âœ“ Shock index (HR/SysBP) - capped at [0, 3]\n",
      "  âœ“ Modified shock index (HR/MAP) - capped at [0, 3]\n",
      "\n",
      "--- Respiratory Features ---\n",
      "  âœ“ Hypoxemia (SpO2 < 90%)\n",
      "  âœ“ Abnormal respiratory rate\n",
      "  âœ“ Respiratory distress score\n",
      "\n",
      "--- Temperature Features ---\n",
      "  âœ“ Fever indicator\n",
      "  âœ“ Hypothermia indicator\n",
      "  âœ“ Temperature range\n",
      "\n",
      "--- Glucose Features ---\n",
      "  âœ“ Glucose variability\n",
      "\n",
      "--- Age-Related Features ---\n",
      "  âœ“ Elderly indicator (>65 years)\n",
      "  âœ“ Age squared\n",
      "\n",
      "--- Vital Sign Variability ---\n",
      "  âœ“ Heart rate range\n",
      "\n",
      "--- Composite Risk Score ---\n",
      "  âœ“ Composite severity score (0-5)\n",
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING COMPLETE\n",
      "======================================================================\n",
      "Original features: 57\n",
      "New features: 72\n",
      "Added: 15 engineered features\n",
      "\n",
      "Engineered features added to numeric_features list for scaling\n",
      "\n",
      "--- Removing Redundant Features ---\n",
      "  âœ“ Dropped RespDistress_Score (redundant with RespRate_Mean)\n",
      "  âœ“ Dropped MeanBP_Mean (redundant with DiasBP_Mean)\n",
      "\n",
      "Removed 2 redundant features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['PulsePressure'] = X['SysBP_Mean'] - X['DiasBP_Mean']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['PulsePressure'] = X_test['SysBP_Mean'] - X_test['DiasBP_Mean']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['SysBP_Range'] = X['SysBP_Max'] - X['SysBP_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['SysBP_Range'] = X_test['SysBP_Max'] - X_test['SysBP_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ShockIndex'] = X['HeartRate_Mean'] / (X['SysBP_Mean'] + 1)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['ShockIndex'] = X_test['HeartRate_Mean'] / (X_test['SysBP_Mean'] + 1)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ShockIndex'] = X['ShockIndex'].clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['ShockIndex'] = X_test['ShockIndex'].clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ModifiedShockIndex'] = X['HeartRate_Mean'] / (X['MeanBP_Mean'] + 1)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['ModifiedShockIndex'] = X_test['HeartRate_Mean'] / (X_test['MeanBP_Mean'] + 1)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ModifiedShockIndex'] = X['ModifiedShockIndex'].clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['ModifiedShockIndex'] = X_test['ModifiedShockIndex'].clip(0, 3)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hypoxemia'] = (X['SpO2_Min'] < 90).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hypoxemia'] = (X_test['SpO2_Min'] < 90).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['RespRate_Abnormal'] = ((X['RespRate_Mean'] < 12) | (X['RespRate_Mean'] > 20)).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['RespRate_Abnormal'] = ((X_test['RespRate_Mean'] < 12) | (X_test['RespRate_Mean'] > 20)).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['RespDistress_Score'] = X['RespRate_Mean'] * (100 - X['SpO2_Mean'])\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['RespDistress_Score'] = X_test['RespRate_Mean'] * (100 - X_test['SpO2_Mean'])\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Fever'] = (X['TempC_Max'] > 38).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Fever'] = (X_test['TempC_Max'] > 38).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Hypothermia'] = (X['TempC_Min'] < 36).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Hypothermia'] = (X_test['TempC_Min'] < 36).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Temp_Range'] = X['TempC_Max'] - X['TempC_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Temp_Range'] = X_test['TempC_Max'] - X_test['TempC_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Glucose_Range'] = X['Glucose_Max'] - X['Glucose_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Glucose_Range'] = X_test['Glucose_Max'] - X_test['Glucose_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Elderly'] = (X['age'] > 65).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Elderly'] = (X_test['age'] > 65).astype(int)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['age_squared'] = X['age'] ** 2\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['age_squared'] = X_test['age'] ** 2\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['HeartRate_Range'] = X['HeartRate_Max'] - X['HeartRate_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['HeartRate_Range'] = X_test['HeartRate_Max'] - X_test['HeartRate_Min']\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Severity_Score'] = sum(severity_components)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_20352\\2250013367.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Severity_Score'] = sum(severity_components_test)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8.5. FEATURE ENGINEERING - MEDICAL DOMAIN KNOWLEDGE\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "original_feature_count = X.shape[1]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Blood Pressure Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Blood Pressure Features ---\")\n",
    "\n",
    "# Pulse Pressure (SysBP - DiasBP) - cardiovascular health indicator\n",
    "if all(col in X.columns for col in ['SysBP_Mean', 'DiasBP_Mean']):\n",
    "    X['PulsePressure'] = X['SysBP_Mean'] - X['DiasBP_Mean']\n",
    "    X_test['PulsePressure'] = X_test['SysBP_Mean'] - X_test['DiasBP_Mean']\n",
    "    print(\"  âœ“ Pulse pressure\")\n",
    "\n",
    "# Blood pressure variability\n",
    "if all(col in X.columns for col in ['SysBP_Min', 'SysBP_Max']):\n",
    "    X['SysBP_Range'] = X['SysBP_Max'] - X['SysBP_Min']\n",
    "    X_test['SysBP_Range'] = X_test['SysBP_Max'] - X_test['SysBP_Min']\n",
    "    print(\"  âœ“ Systolic BP range\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Shock Indices (Critical for ICU mortality prediction)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Shock Indices ---\")\n",
    "\n",
    "# Shock Index = HR / SysBP (>0.9 indicates shock)\n",
    "if all(col in X.columns for col in ['HeartRate_Mean', 'SysBP_Mean']):\n",
    "    X['ShockIndex'] = X['HeartRate_Mean'] / (X['SysBP_Mean'] + 1)\n",
    "    X_test['ShockIndex'] = X_test['HeartRate_Mean'] / (X_test['SysBP_Mean'] + 1)\n",
    "    \n",
    "    # Cap extreme values (clinical range: 0.5-2.0 is reasonable)\n",
    "    X['ShockIndex'] = X['ShockIndex'].clip(0, 3)\n",
    "    X_test['ShockIndex'] = X_test['ShockIndex'].clip(0, 3)\n",
    "    print(\"  âœ“ Shock index (HR/SysBP) - capped at [0, 3]\")\n",
    "\n",
    "# Modified Shock Index = HR / MAP\n",
    "if all(col in X.columns for col in ['HeartRate_Mean', 'MeanBP_Mean']):\n",
    "    X['ModifiedShockIndex'] = X['HeartRate_Mean'] / (X['MeanBP_Mean'] + 1)\n",
    "    X_test['ModifiedShockIndex'] = X_test['HeartRate_Mean'] / (X_test['MeanBP_Mean'] + 1)\n",
    "    \n",
    "    # Cap extreme values\n",
    "    X['ModifiedShockIndex'] = X['ModifiedShockIndex'].clip(0, 3)\n",
    "    X_test['ModifiedShockIndex'] = X_test['ModifiedShockIndex'].clip(0, 3)\n",
    "    print(\"  âœ“ Modified shock index (HR/MAP) - capped at [0, 3]\")\n",
    "    \n",
    "# -----------------------------------------------------------------------------\n",
    "# Respiratory Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Respiratory Features ---\")\n",
    "\n",
    "# Hypoxemia indicator (SpO2 < 90% is clinically significant)\n",
    "if 'SpO2_Min' in X.columns:\n",
    "    X['Hypoxemia'] = (X['SpO2_Min'] < 90).astype(int)\n",
    "    X_test['Hypoxemia'] = (X_test['SpO2_Min'] < 90).astype(int)\n",
    "    print(\"  âœ“ Hypoxemia (SpO2 < 90%)\")\n",
    "\n",
    "# Respiratory rate abnormality (normal: 12-20 breaths/min)\n",
    "if 'RespRate_Mean' in X.columns:\n",
    "    X['RespRate_Abnormal'] = ((X['RespRate_Mean'] < 12) | (X['RespRate_Mean'] > 20)).astype(int)\n",
    "    X_test['RespRate_Abnormal'] = ((X_test['RespRate_Mean'] < 12) | (X_test['RespRate_Mean'] > 20)).astype(int)\n",
    "    print(\"  âœ“ Abnormal respiratory rate\")\n",
    "\n",
    "# Respiratory distress score (high RR + low SpO2)\n",
    "if all(col in X.columns for col in ['RespRate_Mean', 'SpO2_Mean']):\n",
    "    X['RespDistress_Score'] = X['RespRate_Mean'] * (100 - X['SpO2_Mean'])\n",
    "    X_test['RespDistress_Score'] = X_test['RespRate_Mean'] * (100 - X_test['SpO2_Mean'])\n",
    "    print(\"  âœ“ Respiratory distress score\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Temperature Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Temperature Features ---\")\n",
    "\n",
    "# Fever (>38Â°C)\n",
    "if 'TempC_Max' in X.columns:\n",
    "    X['Fever'] = (X['TempC_Max'] > 38).astype(int)\n",
    "    X_test['Fever'] = (X_test['TempC_Max'] > 38).astype(int)\n",
    "    print(\"  âœ“ Fever indicator\")\n",
    "\n",
    "# Hypothermia (<36Â°C)\n",
    "if 'TempC_Min' in X.columns:\n",
    "    X['Hypothermia'] = (X['TempC_Min'] < 36).astype(int)\n",
    "    X_test['Hypothermia'] = (X_test['TempC_Min'] < 36).astype(int)\n",
    "    print(\"  âœ“ Hypothermia indicator\")\n",
    "\n",
    "# Temperature instability\n",
    "if all(col in X.columns for col in ['TempC_Min', 'TempC_Max']):\n",
    "    X['Temp_Range'] = X['TempC_Max'] - X['TempC_Min']\n",
    "    X_test['Temp_Range'] = X_test['TempC_Max'] - X_test['TempC_Min']\n",
    "    print(\"  âœ“ Temperature range\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Glucose Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Glucose Features ---\")\n",
    "\n",
    "\n",
    "\n",
    "# Glucose variability\n",
    "if all(col in X.columns for col in ['Glucose_Min', 'Glucose_Max']):\n",
    "    X['Glucose_Range'] = X['Glucose_Max'] - X['Glucose_Min']\n",
    "    X_test['Glucose_Range'] = X_test['Glucose_Max'] - X_test['Glucose_Min']\n",
    "    print(\"  âœ“ Glucose variability\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Age-Related Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Age-Related Features ---\")\n",
    "\n",
    "# Elderly indicator (>65 years)\n",
    "if 'age' in X.columns:\n",
    "    X['Elderly'] = (X['age'] > 65).astype(int)\n",
    "    X_test['Elderly'] = (X_test['age'] > 65).astype(int)\n",
    "    print(\"  âœ“ Elderly indicator (>65 years)\")\n",
    "    \n",
    "    # Age squared (capture non-linear effects)\n",
    "    X['age_squared'] = X['age'] ** 2\n",
    "    X_test['age_squared'] = X_test['age'] ** 2\n",
    "    print(\"  âœ“ Age squared\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Vital Sign Variability\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Vital Sign Variability ---\")\n",
    "\n",
    "# Heart rate variability\n",
    "if all(col in X.columns for col in ['HeartRate_Min', 'HeartRate_Max']):\n",
    "    X['HeartRate_Range'] = X['HeartRate_Max'] - X['HeartRate_Min']\n",
    "    X_test['HeartRate_Range'] = X_test['HeartRate_Max'] - X_test['HeartRate_Min']\n",
    "    print(\"  âœ“ Heart rate range\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Composite Risk Score\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Composite Risk Score ---\")\n",
    "\n",
    "# Count abnormal vital signs\n",
    "severity_components = []\n",
    "\n",
    "if 'ShockIndex' in X.columns:\n",
    "    severity_components.append((X['ShockIndex'] > 0.9).astype(int))\n",
    "if 'Hypoxemia' in X.columns:\n",
    "    severity_components.append(X['Hypoxemia'])\n",
    "if 'RespRate_Abnormal' in X.columns:\n",
    "    severity_components.append(X['RespRate_Abnormal'])\n",
    "if 'Fever' in X.columns:\n",
    "    severity_components.append(X['Fever'])\n",
    "if 'Hypothermia' in X.columns:\n",
    "    severity_components.append(X['Hypothermia'])\n",
    "\n",
    "if severity_components:\n",
    "    X['Severity_Score'] = sum(severity_components)\n",
    "    \n",
    "    # Repeat for test set\n",
    "    severity_components_test = []\n",
    "    if 'ShockIndex' in X_test.columns:\n",
    "        severity_components_test.append((X_test['ShockIndex'] > 0.9).astype(int))\n",
    "    if 'Hypoxemia' in X_test.columns:\n",
    "        severity_components_test.append(X_test['Hypoxemia'])\n",
    "    if 'RespRate_Abnormal' in X_test.columns:\n",
    "        severity_components_test.append(X_test['RespRate_Abnormal'])\n",
    "    if 'Fever' in X_test.columns:\n",
    "        severity_components_test.append(X_test['Fever'])\n",
    "    if 'Hypothermia' in X_test.columns:\n",
    "        severity_components_test.append(X_test['Hypothermia'])\n",
    "    \n",
    "    X_test['Severity_Score'] = sum(severity_components_test)\n",
    "    print(\"  âœ“ Composite severity score (0-5)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Summary\n",
    "# -----------------------------------------------------------------------------\n",
    "new_feature_count = X.shape[1]\n",
    "added_features = new_feature_count - original_feature_count\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FEATURE ENGINEERING COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Original features: {original_feature_count}\")\n",
    "print(f\"New features: {new_feature_count}\")\n",
    "print(f\"Added: {added_features} engineered features\")\n",
    "\n",
    "# Update numeric_features list to include new engineered features\n",
    "new_engineered_features = [col for col in X.columns if col not in numeric_features + ['ICD9_encoded']]\n",
    "numeric_features.extend(new_engineered_features)\n",
    "\n",
    "print(f\"\\nEngineered features added to numeric_features list for scaling\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Remove Redundant Features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Removing Redundant Features ---\")\n",
    "\n",
    "redundant_features = []\n",
    "\n",
    "# RespDistress_Score is 99.99% correlated with RespRate_Mean\n",
    "# Keep RespRate_Mean (original feature) and drop engineered one\n",
    "if 'RespDistress_Score' in X.columns:\n",
    "    X = X.drop('RespDistress_Score', axis=1)\n",
    "    X_test = X_test.drop('RespDistress_Score', axis=1)\n",
    "    redundant_features.append('RespDistress_Score')\n",
    "    print(\"  âœ“ Dropped RespDistress_Score (redundant with RespRate_Mean)\")\n",
    "\n",
    "# MeanBP_Mean is 90% correlated with DiasBP_Mean\n",
    "# Keep DiasBP_Mean and drop MeanBP_Mean\n",
    "if 'MeanBP_Mean' in X.columns:\n",
    "    X = X.drop('MeanBP_Mean', axis=1)\n",
    "    X_test = X_test.drop('MeanBP_Mean', axis=1)\n",
    "    redundant_features.append('MeanBP_Mean')\n",
    "    print(\"  âœ“ Dropped MeanBP_Mean (redundant with DiasBP_Mean)\")\n",
    "\n",
    "if redundant_features:\n",
    "    print(f\"\\nRemoved {len(redundant_features)} redundant features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4743b5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SCALING NUMERIC FEATURES\n",
      "======================================================================\n",
      "\n",
      "Total numeric features: 41\n",
      "Binary features (will NOT scale): 37\n",
      "Continuous features (will scale): 34\n",
      "\n",
      "âœ“ Scaled 34 continuous features\n",
      "âœ“ Left 37 binary features unscaled\n",
      "\n",
      "Verifying binary features have variance:\n",
      "  Hypoxemia: variance=0.1580, unique_values=2\n",
      "  RespRate_Abnormal: variance=0.2120, unique_values=2\n",
      "  Fever: variance=0.1424, unique_values=2\n",
      "  Hypothermia: variance=0.2331, unique_values=2\n",
      "  Hyperglycemia: variance=0.2307, unique_values=2\n",
      "  Hypoglycemia: variance=0.0757, unique_values=2\n",
      "  Elderly: variance=0.2485, unique_values=2\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. FEATURE SCALING\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCALING NUMERIC FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get all numeric columns\n",
    "all_numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Identify binary features (created in feature engineering)\n",
    "binary_indicator_features = [\n",
    "    'Hypoxemia', 'RespRate_Abnormal', 'Fever', 'Hypothermia',\n",
    "    'Hyperglycemia', 'Hypoglycemia', 'Elderly'\n",
    "]\n",
    "\n",
    "# Also identify one-hot encoded features (they're binary too)\n",
    "one_hot_features = [col for col in X.columns if '_' in col and X[col].nunique() <= 2]\n",
    "\n",
    "# Combine all binary features to EXCLUDE from scaling\n",
    "exclude_from_scaling = binary_indicator_features + one_hot_features\n",
    "\n",
    "# Features to scale = all numeric EXCEPT binary indicators and one-hot encoded\n",
    "features_to_scale = [col for col in all_numeric_cols if col not in exclude_from_scaling]\n",
    "\n",
    "print(f\"\\nTotal numeric features: {len(all_numeric_cols)}\")\n",
    "print(f\"Binary features (will NOT scale): {len(exclude_from_scaling)}\")\n",
    "print(f\"Continuous features (will scale): {len(features_to_scale)}\")\n",
    "\n",
    "# Scale only continuous features\n",
    "scaler = StandardScaler()\n",
    "X[features_to_scale] = scaler.fit_transform(X[features_to_scale])\n",
    "X_test[features_to_scale] = scaler.transform(X_test[features_to_scale])\n",
    "\n",
    "print(f\"\\nâœ“ Scaled {len(features_to_scale)} continuous features\")\n",
    "print(f\"âœ“ Left {len(exclude_from_scaling)} binary features unscaled\")\n",
    "\n",
    "# Verify binary features still have variance\n",
    "print(\"\\nVerifying binary features have variance:\")\n",
    "for feat in binary_indicator_features:\n",
    "    if feat in X.columns:\n",
    "        var = X[feat].var()\n",
    "        unique = X[feat].nunique()\n",
    "        print(f\"  {feat}: variance={var:.4f}, unique_values={unique}\")\n",
    "        if var == 0:\n",
    "            print(f\"    âš ï¸ WARNING: {feat} has zero variance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40a4fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving processed data ---\n",
      "âœ“ Processed data saved to ../data/processed/\n",
      "\n",
      "======================================================================\n",
      "PREPROCESSING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "You can now run modeling notebooks without repeating preprocessing.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. SAVE PROCESSED DATA\n",
    "# =============================================================================\n",
    "print(\"\\n--- Saving processed data ---\")\n",
    "\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save as pickle (preserves dtypes and column names)\n",
    "X.to_pickle('../data/processed/X_train_processed.pkl')\n",
    "y.to_pickle('../data/processed/y_train.pkl')\n",
    "X_test.to_pickle('../data/processed/X_test_processed.pkl')\n",
    "test_ids.to_pickle('../data/processed/test_ids.pkl')\n",
    "\n",
    "# Also save preprocessing objects (to use on new data if needed)\n",
    "with open('../data/processed/numeric_imputer.pkl', 'wb') as f:\n",
    "    pickle.dump(numeric_imputer, f)\n",
    "with open('../data/processed/categorical_imputer.pkl', 'wb') as f:\n",
    "    pickle.dump(categorical_imputer, f)\n",
    "with open('../data/processed/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"âœ“ Processed data saved to ../data/processed/\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYou can now run modeling notebooks without repeating preprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "650cdd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPROCESSING VALIDATION\n",
      "======================================================================\n",
      "\n",
      "--- Check 1: Binary Feature Variance ---\n",
      "  Hypoxemia:\n",
      "    Variance: 0.1580\n",
      "    Unique values: 2 [np.int64(0), np.int64(1)]\n",
      "    âœ“ Valid binary feature\n",
      "  RespRate_Abnormal:\n",
      "    Variance: 0.2120\n",
      "    Unique values: 2 [np.int64(0), np.int64(1)]\n",
      "    âœ“ Valid binary feature\n",
      "  Fever:\n",
      "    Variance: 0.1424\n",
      "    Unique values: 2 [np.int64(0), np.int64(1)]\n",
      "    âœ“ Valid binary feature\n",
      "  Hypothermia:\n",
      "    Variance: 0.2331\n",
      "    Unique values: 2 [np.int64(0), np.int64(1)]\n",
      "    âœ“ Valid binary feature\n",
      "  Hyperglycemia:\n",
      "    Variance: 0.2307\n",
      "    Unique values: 2 [np.int64(0), np.int64(1)]\n",
      "    âœ“ Valid binary feature\n",
      "  Hypoglycemia:\n",
      "    Variance: 0.0757\n",
      "    Unique values: 2 [np.int64(0), np.int64(1)]\n",
      "    âœ“ Valid binary feature\n",
      "  Elderly:\n",
      "    Variance: 0.2485\n",
      "    Unique values: 2 [np.int64(0), np.int64(1)]\n",
      "    âœ“ Valid binary feature\n",
      "\n",
      "--- Check 2: Invalid Values ---\n",
      "  NaN values: 0\n",
      "  Infinite values: 0\n",
      "  âœ“ No NaN values\n",
      "  âœ“ No infinite values\n",
      "\n",
      "--- Check 3: Shock Indices Clipped ---\n",
      "  ShockIndex: [-3.11, 8.91]\n",
      "    âœ“ Properly clipped\n",
      "  ModifiedShockIndex: [-3.24, 8.34]\n",
      "    âœ“ Properly clipped\n",
      "\n",
      "--- Check 4: Redundant Features Dropped ---\n",
      "  âœ“ Redundant features dropped: ['RespDistress_Score', 'MeanBP_Mean']\n",
      "\n",
      "--- Check 5: Feature Count ---\n",
      "  Total features: 70\n",
      "  âœ“ Feature count looks good\n",
      "\n",
      "--- Check 6: Train/Test Consistency ---\n",
      "  âœ“ Train and test have same number of features: 70\n",
      "  âœ“ Train and test have identical column names\n",
      "\n",
      "--- Check 7: Scaling Quality ---\n",
      "  HeartRate_Mean: mean=0.0000, std=1.0000\n",
      "  SysBP_Mean: mean=0.0000, std=1.0000\n",
      "  age: mean=0.0000, std=1.0000\n",
      "  Glucose_Mean: mean=-0.0000, std=1.0000\n",
      "\n",
      "--- Check 8: Target Distribution ---\n",
      "  Mortality rate: 0.112 (2345/20885)\n",
      "  âœ“ Target distribution matches expected: ~11.2%\n",
      "\n",
      "======================================================================\n",
      "âœ… ALL VALIDATION CHECKS PASSED!\n",
      "======================================================================\n",
      "\n",
      "ðŸŽ‰ Preprocessing completed successfully!\n",
      "   Ready to train models with confidence.\n",
      "\n",
      "======================================================================\n",
      "FEATURE PREVIEW\n",
      "======================================================================\n",
      "\n",
      "Dataset shapes:\n",
      "  X_train: (20885, 70)\n",
      "  y_train: (20885,)\n",
      "  X_test: (5221, 70)\n",
      "  test_ids: 5221\n",
      "\n",
      "Sample features (first 15):\n",
      "   1. HeartRate_Min\n",
      "   2. HeartRate_Max\n",
      "   3. HeartRate_Mean\n",
      "   4. SysBP_Min\n",
      "   5. SysBP_Max\n",
      "   6. SysBP_Mean\n",
      "   7. DiasBP_Min\n",
      "   8. DiasBP_Max\n",
      "   9. DiasBP_Mean\n",
      "  10. MeanBP_Min\n",
      "  11. MeanBP_Max\n",
      "  12. RespRate_Min\n",
      "  13. RespRate_Max\n",
      "  14. RespRate_Mean\n",
      "  15. TempC_Min\n",
      "\n",
      "Feature types:\n",
      "  Binary features: 36\n",
      "  Continuous features: 34\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 9. VALIDATION - CHECK PREPROCESSING QUALITY\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "validation_passed = True\n",
    "issues = []\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Check 1: Binary features should have variance > 0\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Check 1: Binary Feature Variance ---\")\n",
    "\n",
    "binary_features_to_check = [\n",
    "    'Hypoxemia', 'RespRate_Abnormal', 'Fever', 'Hypothermia',\n",
    "    'Hyperglycemia', 'Hypoglycemia', 'Elderly'\n",
    "]\n",
    "\n",
    "for feat in binary_features_to_check:\n",
    "    if feat in X.columns:\n",
    "        variance = X[feat].var()\n",
    "        unique_vals = X[feat].nunique()\n",
    "        unique_set = set(X[feat].unique())\n",
    "        \n",
    "        print(f\"  {feat}:\")\n",
    "        print(f\"    Variance: {variance:.4f}\")\n",
    "        print(f\"    Unique values: {unique_vals} {sorted(unique_set)}\")\n",
    "        \n",
    "        if variance == 0:\n",
    "            issues.append(f\"âŒ {feat} has ZERO variance (constant)\")\n",
    "            validation_passed = False\n",
    "        elif unique_vals == 1:\n",
    "            issues.append(f\"âŒ {feat} only has one value: {list(unique_set)[0]}\")\n",
    "            validation_passed = False\n",
    "        elif not unique_set.issubset({0, 1, 0.0, 1.0}):\n",
    "            issues.append(f\"âŒ {feat} is not binary: {sorted(unique_set)[:5]}\")\n",
    "            validation_passed = False\n",
    "        else:\n",
    "            print(f\"    âœ“ Valid binary feature\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Check 2: No NaN or Inf values\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Check 2: Invalid Values ---\")\n",
    "\n",
    "nan_count = X.isnull().sum().sum()\n",
    "inf_count = np.isinf(X.select_dtypes(include=[np.number])).sum().sum()\n",
    "\n",
    "print(f\"  NaN values: {nan_count}\")\n",
    "print(f\"  Infinite values: {inf_count}\")\n",
    "\n",
    "if nan_count > 0:\n",
    "    nan_cols = X.isnull().sum()[X.isnull().sum() > 0]\n",
    "    issues.append(f\"âŒ {nan_count} NaN values in: {list(nan_cols.index)}\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(\"  âœ“ No NaN values\")\n",
    "\n",
    "if inf_count > 0:\n",
    "    inf_cols = X.select_dtypes(include=[np.number]).columns[\n",
    "        np.isinf(X.select_dtypes(include=[np.number])).any()\n",
    "    ]\n",
    "    issues.append(f\"âŒ {inf_count} Infinite values in: {list(inf_cols)}\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(\"  âœ“ No infinite values\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Check 3: Shock indices were clipped\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Check 3: Shock Indices Clipped ---\")\n",
    "\n",
    "shock_features = ['ShockIndex', 'ModifiedShockIndex']\n",
    "for feat in shock_features:\n",
    "    if feat in X.columns:\n",
    "        min_val = X[feat].min()\n",
    "        max_val = X[feat].max()\n",
    "        print(f\"  {feat}: [{min_val:.2f}, {max_val:.2f}]\")\n",
    "        \n",
    "        if max_val > 10:\n",
    "            issues.append(f\"âŒ {feat} not clipped: max={max_val:.2f}\")\n",
    "            validation_passed = False\n",
    "        else:\n",
    "            print(f\"    âœ“ Properly clipped\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Check 4: Redundant features were dropped\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Check 4: Redundant Features Dropped ---\")\n",
    "\n",
    "should_be_dropped = ['RespDistress_Score', 'MeanBP_Mean']\n",
    "still_present = [f for f in should_be_dropped if f in X.columns]\n",
    "\n",
    "if still_present:\n",
    "    issues.append(f\"âŒ Redundant features still present: {still_present}\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(f\"  âœ“ Redundant features dropped: {should_be_dropped}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Check 5: Feature count is reasonable\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Check 5: Feature Count ---\")\n",
    "\n",
    "n_features = X.shape[1]\n",
    "print(f\"  Total features: {n_features}\")\n",
    "\n",
    "if n_features < 50:\n",
    "    issues.append(f\"âš ï¸ Only {n_features} features - might be too few\")\n",
    "elif n_features > 100:\n",
    "    issues.append(f\"âš ï¸ {n_features} features - might be too many\")\n",
    "else:\n",
    "    print(f\"  âœ“ Feature count looks good\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Check 6: Train and test have same features\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Check 6: Train/Test Consistency ---\")\n",
    "\n",
    "if X.shape[1] != X_test.shape[1]:\n",
    "    issues.append(f\"âŒ Shape mismatch: Train {X.shape[1]} vs Test {X_test.shape[1]} features\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(f\"  âœ“ Train and test have same number of features: {X.shape[1]}\")\n",
    "\n",
    "if list(X.columns) != list(X_test.columns):\n",
    "    issues.append(f\"âŒ Train and test have different column names\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(f\"  âœ“ Train and test have identical column names\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Check 7: Scaled features look normalized\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Check 7: Scaling Quality ---\")\n",
    "\n",
    "# Sample a few continuous features\n",
    "continuous_sample = ['HeartRate_Mean', 'SysBP_Mean', 'age', 'Glucose_Mean']\n",
    "for feat in continuous_sample:\n",
    "    if feat in X.columns:\n",
    "        mean = X[feat].mean()\n",
    "        std = X[feat].std()\n",
    "        print(f\"  {feat}: mean={mean:.4f}, std={std:.4f}\")\n",
    "        \n",
    "        # Scaled features should have meanâ‰ˆ0, stdâ‰ˆ1\n",
    "        if abs(mean) > 0.1 or abs(std - 1.0) > 0.1:\n",
    "            issues.append(f\"âš ï¸ {feat} might not be properly scaled\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Check 8: Target distribution unchanged\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Check 8: Target Distribution ---\")\n",
    "\n",
    "target_mean = y.mean()\n",
    "target_count = y.sum()\n",
    "print(f\"  Mortality rate: {target_mean:.3f} ({target_count}/{len(y)})\")\n",
    "\n",
    "expected_mortality = 0.112  # From your original data\n",
    "if abs(target_mean - expected_mortality) > 0.01:\n",
    "    issues.append(f\"âš ï¸ Target distribution changed: {target_mean:.3f} vs expected {expected_mortality:.3f}\")\n",
    "else:\n",
    "    print(f\"  âœ“ Target distribution matches expected: ~11.2%\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# FINAL VERDICT\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if validation_passed and len(issues) == 0:\n",
    "    print(\"âœ… ALL VALIDATION CHECKS PASSED!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nðŸŽ‰ Preprocessing completed successfully!\")\n",
    "    print(\"   Ready to train models with confidence.\")\n",
    "else:\n",
    "    print(\"ðŸš¨ VALIDATION ISSUES FOUND\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if issues:\n",
    "        print(\"\\nIssues to fix:\")\n",
    "        for i, issue in enumerate(issues, 1):\n",
    "            print(f\"{i}. {issue}\")\n",
    "    \n",
    "    print(\"\\nâš ï¸ DO NOT train models until these issues are resolved!\")\n",
    "    print(\"   Review the preprocessing pipeline and fix the issues above.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Quick feature preview\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE PREVIEW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDataset shapes:\")\n",
    "print(f\"  X_train: {X.shape}\")\n",
    "print(f\"  y_train: {y.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  test_ids: {len(test_ids)}\")\n",
    "\n",
    "print(f\"\\nSample features (first 15):\")\n",
    "for i, col in enumerate(X.columns[:15], 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nFeature types:\")\n",
    "binary_count = sum(X[col].nunique() == 2 for col in X.columns)\n",
    "print(f\"  Binary features: {binary_count}\")\n",
    "print(f\"  Continuous features: {X.shape[1] - binary_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classification _HEF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
